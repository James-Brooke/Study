{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from operator import itemgetter\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,)) #normalise pixels using mean and stdev\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #normalise to range -1 to 1\n",
    "                   ])\n",
    "\n",
    "\n",
    "\n",
    "MNIST_train = datasets.MNIST(r'D:\\Data_sets/MNIST', train=True, download=True,\n",
    "                   transform=transform)\n",
    "\n",
    "MNIST_test = datasets.MNIST(r'D:\\Data_sets/MNIST', train=False, download=True,\n",
    "                   transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(MNIST_train, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(MNIST_test,\n",
    "                                          batch_size=1000, \n",
    "                                          shuffle=True, \n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LAYER_SPACE = {\n",
    "    'nb_units':{'lb': 128, 'ub':1024, 'mutate': 0.15},\n",
    "    'dropout_rate': {'lb': 0.0, 'ub': 0.7, 'mutate': 0.2},\n",
    "    'activation': {'func': ['linear','tanh','relu','sigmoid','elu'], 'mutate':0.2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NET_SPACE = {\n",
    "    'nb_layers': {'lb': 1, 'ub': 3, 'mutate': 0.15},\n",
    "    'lr': {'lb': 0.001, 'ub':0.1, 'mutate': 0.15},\n",
    "    'weight_decay': {'lb': 0.00001, 'ub': 0.0004, 'mutate':0.2},\n",
    "    'optimizer': {'func': ['sgd', 'adam', 'adadelta','rmsprop'], 'mutate': 0.2}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Randomise network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def random_value(space):\n",
    "    \"\"\"Returns random value from space.\"\"\"\n",
    "    \n",
    "    val = None\n",
    "    \n",
    "    if 'func' in space: #randomise optimiser or activation function\n",
    "        val = random.sample(space['func'], 1)[0] \n",
    "    \n",
    "    elif isinstance(space['lb'], int): #randomise number of units or layers\n",
    "        val = random.randint(space['lb'], space['ub'])\n",
    "    \n",
    "    else: #randomise percentages, i.e. dropout rates or weight decay\n",
    "        val = random.random() * (space['ub'] - space['lb']) + space['lb']\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def randomize_network(layer_space, net_space): \n",
    "    \"\"\"Returns a randomised neural network\"\"\"\n",
    "    net = {}\n",
    "    \n",
    "    for key in net_space.keys():\n",
    "        net[key] = random_value(net_space[key])\n",
    "        \n",
    "    layers = []\n",
    "    \n",
    "    for i in range(net['nb_layers']):\n",
    "        layer = {}\n",
    "        for key in layer_space.keys():\n",
    "            layer[key] = random_value(layer_space[key])\n",
    "        layers.append(layer)\n",
    "        net['layers'] = layers\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [{'activation': 'elu',\n",
       "   'dropout_rate': 0.2953273247779448,\n",
       "   'nb_units': 863},\n",
       "  {'activation': 'sigmoid',\n",
       "   'dropout_rate': 0.49018793842203023,\n",
       "   'nb_units': 288}],\n",
       " 'lr': 0.03850809968690585,\n",
       " 'nb_layers': 2,\n",
       " 'optimizer': 'rmsprop',\n",
       " 'weight_decay': 0.0002889649100417271}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomize_network(LAYER_SPACE, NET_SPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mutate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mutate_net(nnet, layer_space, net_space):\n",
    "    \n",
    "    net = copy.deepcopy(nnet)\n",
    "    \n",
    "    \n",
    "    # mutate optimizer\n",
    "    for k in ['lr', 'weight_decay', 'optimizer']:\n",
    "        if random.random() < net_space[k]['mutate']:\n",
    "            net[k] = random_value(net_space[k])\n",
    "    \n",
    "    \n",
    "    # mutate layers\n",
    "    for layer in net['layers']:\n",
    "        for k in layer_space.keys():\n",
    "            if random.random() < layer_space[k]['mutate']:\n",
    "                layer[k] = random_value(layer_space[k])\n",
    "                \n",
    "                \n",
    "    # mutate number of layers -- 50% add 50% remove\n",
    "    if random.random() < net_space['nb_layers']['mutate']:\n",
    "        if net['nb_layers'] <= net_space['nb_layers']['ub']:\n",
    "            if random.random()< 0.5 and \\\n",
    "            net['nb_layers'] < net_space['nb_layers']['ub']:\n",
    "                layer = {}\n",
    "                for key in layer_space.keys():\n",
    "                    layer[key] = random_value(layer_space[key])\n",
    "                net['layers'].append(layer)      \n",
    "            else:\n",
    "                if net['nb_layers'] > 1:\n",
    "                    net['layers'].pop()\n",
    "\n",
    "                \n",
    "            # value & id update\n",
    "            net['nb_layers'] = len(net['layers'])         \n",
    "            \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \"\"\"Flattens input to vector size (batchsize, 1)\n",
    "    (for use in NetFromBuildInfo).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NetFromBuildInfo(nn.Module):\n",
    "    def __init__(self, build_info):\n",
    "        super(NetFromBuildInfo, self).__init__()\n",
    "        \n",
    "        self.activation_dict = {\n",
    "            'tanh': nn.Tanh(),\n",
    "            'relu': nn.ReLU(),\n",
    "            'sigmoid': nn.Sigmoid(),\n",
    "            'elu': nn.ELU()\n",
    "            }\n",
    "\n",
    "        #NETWORK DEFINITION\n",
    "        \n",
    "        previous_units = 28 * 28 #MNIST shape\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module('flatten', Flatten())\n",
    "         \n",
    "        for i, layer_info in enumerate(build_info['layers']):\n",
    "            i = str(i)\n",
    "            \n",
    "            self.model.add_module(\n",
    "                'fc_' + i,\n",
    "                nn.Linear(previous_units, layer_info['nb_units'])\n",
    "                )\n",
    "            \n",
    "            previous_units = layer_info['nb_units']\n",
    "            \n",
    "            self.model.add_module(\n",
    "                'dropout_' + i,\n",
    "                nn.Dropout(p=layer_info['dropout_rate'])\n",
    "                )\n",
    "            if layer_info['activation'] == 'linear':\n",
    "                continue #linear activation is identity function\n",
    "            self.model.add_module(\n",
    "                layer_info['activation']+ i,\n",
    "                self.activation_dict[layer_info['activation']])\n",
    "\n",
    "        self.model.add_module(\n",
    "            'logits',\n",
    "            nn.Linear(previous_units, 10) #10 MNIST classes\n",
    "            )\n",
    "        \n",
    "        \n",
    "        ##OPTIMIZER\n",
    "\n",
    "        self.opt_args = {#'params': self.model.parameters(),\n",
    "                 'weight_decay': build_info['weight_decay'],\n",
    "                 'lr': build_info['lr']\n",
    "                 }\n",
    "        \n",
    "        self.optimizer_dict = {\n",
    "            'adam': optim.Adam(self.model.parameters(),**self.opt_args),\n",
    "            'rmsprop': optim.RMSprop(self.model.parameters(),**self.opt_args),\n",
    "            'adadelta':optim.Adadelta(self.model.parameters(),**self.opt_args),\n",
    "            'sgd': optim.SGD(self.model.parameters(), **self.opt_args, momentum=0.9) #momentum to train faster\n",
    "            }\n",
    "\n",
    "        self.optimizer = self.optimizer_dict[build_info['optimizer']]\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train test helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss /= len(train_loader.dataset)    \n",
    "    \n",
    "    if epoch % 3 == 0:\n",
    "        print('Train Epoch: {} \\t Loss: {:.6f}'.format(epoch, running_loss ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    \n",
    "    model.train(False)\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    \n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evolution optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TournamentOptimizer:\n",
    "    \"\"\"Define a tournament play selection process.\"\"\"\n",
    "\n",
    "    def __init__(self, population_sz, layer_space, net_space, init_fn, mutate_fn, builder_fn,\n",
    "                 train_fn, test_fn, dataloader, testloader):\n",
    "        \n",
    "        self.init_fn = init_fn\n",
    "        self.layer_space = layer_space\n",
    "        self.net_space = net_space\n",
    "        self.mutate_fn = mutate_fn\n",
    "        self.builder_fn = builder_fn\n",
    "        self.train = train_fn\n",
    "        self.test = test_fn\n",
    "        self.dataloader = dataloader\n",
    "        self.testloader = testloader\n",
    "        self.population_sz = population_sz\n",
    "        \n",
    "        torch.manual_seed(1);\n",
    "        \n",
    "        self.genomes = [init_fn(self.layer_space, self.net_space) for i in range(population_sz)]   \n",
    "        self.population = [NetFromBuildInfo(i).cuda() for i in self.genomes] #randomize population of nets     \n",
    "        \n",
    "        self.test_results = {} \n",
    "        self.genome_history = {} \n",
    "\n",
    "        self.generation = 0\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Tournament evolution step.\"\"\"\n",
    "\n",
    "        genome_holder = [] \n",
    "        \n",
    "        self.generation += 1\n",
    "        \n",
    "        self.genome_history[self.generation] = self.genomes\n",
    "\n",
    "        self.train_nets()\n",
    "        self.evaluate_nets()\n",
    "\n",
    "        mean = np.mean(self.test_results[self.generation]['correct'])\n",
    "        best = np.max(self.test_results[self.generation]['correct'])\n",
    "        \n",
    "        print('\\nPopulation mean:{} max:{}'.format(mean, best))\n",
    "        \n",
    "        \n",
    "        children = []\n",
    "        n_elite = 2\n",
    "        sorted_pop = np.argsort(self.test_results[self.generation]['correct'])[::-1]\n",
    "        elite = sorted_pop[:n_elite]\n",
    "        \n",
    "\n",
    "\n",
    "        # elites always included in the next population\n",
    "        self.elite = []\n",
    "        print('\\nTop performers:')\n",
    "        for no, i in enumerate(elite):\n",
    "            self.elite.append((self.test_results[self.generation]['correct'][i], \n",
    "                               self.population[i]))    \n",
    "            \n",
    "            genome_holder.append(self.genomes[i])\n",
    "            \n",
    "            print(\"{}: score:{}\".format(no, self.test_results[self.generation]['correct'][i]))   \n",
    "            \n",
    "            children.append(self.population[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "        #https://stackoverflow.com/questions/31933784/tournament-selection-in-genetic-algorithm\n",
    "        p = 0.85 # winner probability \n",
    "        tournament_size = 3\n",
    "        probs = [p*((1-p)**i) for i in range(tournament_size-1)]\n",
    "        probs.append(1-np.sum(probs))\n",
    "        #probs = [0.85, 0.1275, 0.0224]\n",
    "        \n",
    "        while len(children) < self.population_sz:\n",
    "            pop = range(len(self.population))\n",
    "            sel_k = random.sample(pop, k=tournament_size)\n",
    "            fitness_k = list(np.array(self.test_results[self.generation]['correct'])[sel_k])\n",
    "            selected = zip(sel_k, fitness_k)\n",
    "            rank = sorted(selected, key=itemgetter(1), reverse=True)\n",
    "            pick = np.random.choice(tournament_size, size=1, p=probs)[0]\n",
    "            best = rank[pick][0]\n",
    "            genome = self.mutate_fn(self.genomes[best], self.layer_space, self.net_space)\n",
    "            print('mutated: ', best)\n",
    "            \n",
    "            genome_holder.append(genome)\n",
    "            model =  self.builder_fn(genome).cuda()\n",
    "            children.append(model)\n",
    "\n",
    "\n",
    "            \n",
    "        self.population = children\n",
    "        self.genomes = genome_holder\n",
    "\n",
    "        \n",
    "        #<----------- add all new genomes to genome history --------->\n",
    "        \n",
    "    def train_nets(self):\n",
    "        \n",
    "        for i, net in enumerate(self.population):\n",
    "            for epoch in range(1, 2):\n",
    "                \n",
    "                torch.manual_seed(1);\n",
    "                \n",
    "                self.train(net, self.dataloader, net.optimizer, epoch)\n",
    "                print('model {} trained'.format(i))\n",
    "                \n",
    "                fp = r\"D:\\Models\\NeuroEvolution/{}-{}\".format(self.generation, i)\n",
    "                torch.save(net.state_dict(), fp)\n",
    "                \n",
    "                \n",
    "                \n",
    "    def evaluate_nets(self):\n",
    "        \"\"\"evaluate the models.\"\"\"\n",
    "        \n",
    "        losses = []\n",
    "        corrects = []\n",
    "        \n",
    "        self.test_results[self.generation] = {}\n",
    "        \n",
    "        for i in range(len(self.population)):\n",
    "            net = self.population[i]\n",
    "            loss, correct = self.test(net, self.testloader)\n",
    "            \n",
    "            losses.append(loss)\n",
    "            corrects.append(correct)\n",
    "        \n",
    "        self.test_results[self.generation]['losses'] = losses\n",
    "        self.test_results[self.generation]['correct'] = corrects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = TournamentOptimizer(10, LAYER_SPACE, NET_SPACE, randomize_network, \n",
    "                           mutate_net, NetFromBuildInfo, train, test,\n",
    "                          train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "\n",
      "Population mean:5932.0 max:9351\n",
      "\n",
      "Top performers:\n",
      "0: score:9351\n",
      "1: score:9238\n",
      "mutated:  9\n",
      "mutated:  9\n",
      "mutated:  5\n",
      "mutated:  7\n",
      "mutated:  0\n",
      "mutated:  7\n",
      "mutated:  2\n",
      "mutated:  6\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "\n",
      "Population mean:6945.1 max:9511\n",
      "\n",
      "Top performers:\n",
      "0: score:9511\n",
      "1: score:9457\n",
      "mutated:  4\n",
      "mutated:  2\n",
      "mutated:  0\n",
      "mutated:  5\n",
      "mutated:  0\n",
      "mutated:  0\n",
      "mutated:  4\n",
      "mutated:  5\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    testing.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rebuild_from_save(optimizer, generation, position):\n",
    "    \n",
    "    genome = optimizer.genome_history[generation][position]\n",
    "    \n",
    "    net = NetFromBuildInfo(genome)\n",
    "    \n",
    "    net.load_state_dict(torch.load(r\"D:\\Models\\NeuroEvolution\\{}-{}\".format(generation, position)))\n",
    "    \n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanity_check(optimizer, test_loader):\n",
    "    \n",
    "    for generation in optimizer.test_results:\n",
    "        print('generation 1: \\n')\n",
    "        for i, result in enumerate(optimizer.test_results[generation]['correct']):\n",
    "            \n",
    "            mod = rebuild_from_save(optimizer, generation, i)\n",
    "            _, rebuild_result = test(mod, test_loader)\n",
    "            \n",
    "            if result == rebuild_result:\n",
    "                print(\"result = {}, rebuild result = {}. (equal)\".format(result, rebuild_result))\n",
    "            else:\n",
    "                print(\"result = {}, rebuild result = {}. (different!!)\".format(result, rebuild_result))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation 1: \n",
      "\n",
      "result = 9138, rebuild result = 9138\n",
      "result = 958, rebuild result = 958\n",
      "result = 1212, rebuild result = 1212\n",
      "result = 9096, rebuild result = 9096\n",
      "result = 1032, rebuild result = 1032\n",
      "result = 9238, rebuild result = 9238\n",
      "result = 1009, rebuild result = 1009\n",
      "result = 9178, rebuild result = 9178\n",
      "result = 9108, rebuild result = 9108\n",
      "result = 9351, rebuild result = 9351\n",
      "generation 1: \n",
      "\n",
      "result = 9511, rebuild result = 9511\n",
      "result = 9457, rebuild result = 9457\n",
      "result = 9368, rebuild result = 9368\n",
      "result = 9371, rebuild result = 9371\n",
      "result = 9218, rebuild result = 9218\n",
      "result = 9175, rebuild result = 9175\n",
      "result = 2217, rebuild result = 2217\n",
      "result = 9167, rebuild result = 9167\n",
      "result = 958, rebuild result = 958\n",
      "result = 1009, rebuild result = 1009\n"
     ]
    }
   ],
   "source": [
    "sanity_check(testing, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ads = np.load('D:/Data_sets/Adversarial/MNIST/adversarials.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2183dffc2b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPkAAAD3CAYAAADfRfLgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2183dee4588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ads[0].reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
