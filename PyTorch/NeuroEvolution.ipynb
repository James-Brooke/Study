{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from operator import itemgetter\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Clean MNIST loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,)) #normalise pixels using mean and stdev\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #normalise to range -1 to 1\n",
    "                   ])\n",
    "\n",
    "\n",
    "\n",
    "MNIST_train = datasets.MNIST(r'D:\\Data_sets/MNIST', train=True, download=True,\n",
    "                   transform=transform)\n",
    "\n",
    "MNIST_test = datasets.MNIST(r'D:\\Data_sets/MNIST', train=False, download=True,\n",
    "                   transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(MNIST_train, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(MNIST_test,\n",
    "                                          batch_size=1000, \n",
    "                                          shuffle=True, \n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Adversarial loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class AdversarialDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"FGSM adversarials of MNIST test set\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "\n",
    "        self.adversarials = np.load(root_dir+'/adversarials.npy')\n",
    "        self.labels = np.load(root_dir+'/labels.npy')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.adversarials[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adversarials = AdversarialDataset('D:/Data_sets/Adversarial/MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adversarial_loader = torch.utils.data.DataLoader(adversarials, \n",
    "                                           batch_size=1000, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LAYER_SPACE = {\n",
    "    'nb_units':{'lb': 128, 'ub':1024, 'mutate': 0.15},\n",
    "    'dropout_rate': {'lb': 0.0, 'ub': 0.7, 'mutate': 0.2},\n",
    "    'activation': {'func': ['linear','tanh','relu','sigmoid','elu'], 'mutate':0.2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NET_SPACE = {\n",
    "    'nb_layers': {'lb': 1, 'ub': 3, 'mutate': 0.15},\n",
    "    'lr': {'lb': 0.001, 'ub':0.1, 'mutate': 0.15},\n",
    "    'weight_decay': {'lb': 0.00001, 'ub': 0.0004, 'mutate':0.2},\n",
    "    'optimizer': {'func': ['sgd', 'adam', 'adadelta','rmsprop'], 'mutate': 0.2}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Randomise network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def random_value(space):\n",
    "    \"\"\"Returns random value from space.\"\"\"\n",
    "    \n",
    "    val = None\n",
    "    \n",
    "    if 'func' in space: #randomise optimiser or activation function\n",
    "        val = random.sample(space['func'], 1)[0] \n",
    "    \n",
    "    elif isinstance(space['lb'], int): #randomise number of units or layers\n",
    "        val = random.randint(space['lb'], space['ub'])\n",
    "    \n",
    "    else: #randomise percentages, i.e. dropout rates or weight decay\n",
    "        val = random.random() * (space['ub'] - space['lb']) + space['lb']\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def randomize_network(layer_space, net_space): \n",
    "    \"\"\"Returns a randomised neural network\"\"\"\n",
    "    net = {}\n",
    "    \n",
    "    for key in net_space.keys():\n",
    "        net[key] = random_value(net_space[key])\n",
    "        \n",
    "    layers = []\n",
    "    \n",
    "    for i in range(net['nb_layers']):\n",
    "        layer = {}\n",
    "        for key in layer_space.keys():\n",
    "            layer[key] = random_value(layer_space[key])\n",
    "        layers.append(layer)\n",
    "        net['layers'] = layers\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [{'activation': 'linear',\n",
       "   'dropout_rate': 0.05875328570846247,\n",
       "   'nb_units': 244},\n",
       "  {'activation': 'linear',\n",
       "   'dropout_rate': 0.10278691060470113,\n",
       "   'nb_units': 443},\n",
       "  {'activation': 'sigmoid',\n",
       "   'dropout_rate': 0.5430231617074555,\n",
       "   'nb_units': 312}],\n",
       " 'lr': 0.08548772787644217,\n",
       " 'nb_layers': 3,\n",
       " 'optimizer': 'adadelta',\n",
       " 'weight_decay': 0.00020324598051495654}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomize_network(LAYER_SPACE, NET_SPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mutate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mutate_net(nnet, layer_space, net_space):\n",
    "    \n",
    "    net = copy.deepcopy(nnet)\n",
    "    \n",
    "    \n",
    "    # mutate optimizer\n",
    "    for k in ['lr', 'weight_decay', 'optimizer']:\n",
    "        if random.random() < net_space[k]['mutate']:\n",
    "            net[k] = random_value(net_space[k])\n",
    "    \n",
    "    \n",
    "    # mutate layers\n",
    "    for layer in net['layers']:\n",
    "        for k in layer_space.keys():\n",
    "            if random.random() < layer_space[k]['mutate']:\n",
    "                layer[k] = random_value(layer_space[k])\n",
    "                \n",
    "                \n",
    "    # mutate number of layers -- 50% add 50% remove\n",
    "    if random.random() < net_space['nb_layers']['mutate']:\n",
    "        if net['nb_layers'] <= net_space['nb_layers']['ub']:\n",
    "            if random.random()< 0.5 and \\\n",
    "            net['nb_layers'] < net_space['nb_layers']['ub']:\n",
    "                layer = {}\n",
    "                for key in layer_space.keys():\n",
    "                    layer[key] = random_value(layer_space[key])\n",
    "                net['layers'].append(layer)      \n",
    "            else:\n",
    "                if net['nb_layers'] > 1:\n",
    "                    net['layers'].pop()\n",
    "\n",
    "                \n",
    "            # value & id update\n",
    "            net['nb_layers'] = len(net['layers'])         \n",
    "            \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \"\"\"Flattens input to vector size (batchsize, 1)\n",
    "    (for use in NetFromBuildInfo).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NetFromBuildInfo(nn.Module):\n",
    "    def __init__(self, build_info):\n",
    "        super(NetFromBuildInfo, self).__init__()\n",
    "        \n",
    "        self.activation_dict = {\n",
    "            'tanh': nn.Tanh(),\n",
    "            'relu': nn.ReLU(),\n",
    "            'sigmoid': nn.Sigmoid(),\n",
    "            'elu': nn.ELU()\n",
    "            }\n",
    "\n",
    "        #NETWORK DEFINITION\n",
    "        \n",
    "        previous_units = 28 * 28 #MNIST shape\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module('flatten', Flatten())\n",
    "         \n",
    "        for i, layer_info in enumerate(build_info['layers']):\n",
    "            i = str(i)\n",
    "            \n",
    "            self.model.add_module(\n",
    "                'fc_' + i,\n",
    "                nn.Linear(previous_units, layer_info['nb_units'])\n",
    "                )\n",
    "            \n",
    "            previous_units = layer_info['nb_units']\n",
    "            \n",
    "            self.model.add_module(\n",
    "                'dropout_' + i,\n",
    "                nn.Dropout(p=layer_info['dropout_rate'])\n",
    "                )\n",
    "            if layer_info['activation'] == 'linear':\n",
    "                continue #linear activation is identity function\n",
    "            self.model.add_module(\n",
    "                layer_info['activation']+ i,\n",
    "                self.activation_dict[layer_info['activation']])\n",
    "\n",
    "        self.model.add_module(\n",
    "            'logits',\n",
    "            nn.Linear(previous_units, 10) #10 MNIST classes\n",
    "            )\n",
    "        \n",
    "        \n",
    "        ##OPTIMIZER\n",
    "\n",
    "        self.opt_args = {#'params': self.model.parameters(),\n",
    "                 'weight_decay': build_info['weight_decay'],\n",
    "                 'lr': build_info['lr']\n",
    "                 }\n",
    "        \n",
    "        self.optimizer_dict = {\n",
    "            'adam': optim.Adam(self.model.parameters(),**self.opt_args),\n",
    "            'rmsprop': optim.RMSprop(self.model.parameters(),**self.opt_args),\n",
    "            'adadelta':optim.Adadelta(self.model.parameters(),**self.opt_args),\n",
    "            'sgd': optim.SGD(self.model.parameters(), **self.opt_args, momentum=0.9) #momentum to train faster\n",
    "            }\n",
    "\n",
    "        self.optimizer = self.optimizer_dict[build_info['optimizer']]\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train test helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss /= len(train_loader.dataset)    \n",
    "    \n",
    "    if epoch % 3 == 0:\n",
    "        print('Train Epoch: {} \\t Loss: {:.6f}'.format(epoch, running_loss ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    \n",
    "    model.train(False)\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    \n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evolution optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TournamentOptimizer:\n",
    "    \"\"\"Define a tournament play selection process.\"\"\"\n",
    "\n",
    "    def __init__(self, population_sz, layer_space, net_space, init_fn, mutate_fn, builder_fn,\n",
    "                 train_fn, test_fn, data_loader, test_loader, adversarial_loader):\n",
    "        \n",
    "        self.init_fn = init_fn\n",
    "        self.layer_space = layer_space\n",
    "        self.net_space = net_space\n",
    "        self.mutate_fn = mutate_fn\n",
    "        self.builder_fn = builder_fn\n",
    "        self.train = train_fn\n",
    "        self.test = test_fn\n",
    "        self.dataloader = data_loader\n",
    "        self.testloader = test_loader\n",
    "        self.population_sz = population_sz\n",
    "        self.adversarials = adversarial_loader\n",
    "        \n",
    "        torch.manual_seed(1);\n",
    "        \n",
    "        self.genomes = [init_fn(self.layer_space, self.net_space) for i in range(population_sz)]   \n",
    "        self.population = [NetFromBuildInfo(i).cuda() for i in self.genomes] #randomize population of nets     \n",
    "        \n",
    "        self.test_results = {} \n",
    "        self.genome_history = {} \n",
    "\n",
    "        self.generation = 0\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Tournament evolution step.\"\"\"\n",
    "\n",
    "        genome_holder = [] \n",
    "        \n",
    "        self.generation += 1\n",
    "        \n",
    "        self.genome_history[self.generation] = self.genomes\n",
    "\n",
    "        self.train_nets()\n",
    "        self.evaluate_nets()\n",
    "\n",
    "        mean = np.mean(self.test_results[self.generation]['correct'])\n",
    "        best = np.max(self.test_results[self.generation]['correct'])\n",
    "        \n",
    "        print('\\nPopulation mean:{} max:{}'.format(mean, best))\n",
    "        \n",
    "        \n",
    "        children = []\n",
    "        n_elite = 2\n",
    "        sorted_pop = np.argsort(self.test_results[self.generation]['correct'])[::-1]\n",
    "        elite = sorted_pop[:n_elite]\n",
    "        \n",
    "\n",
    "\n",
    "        # elites always included in the next population\n",
    "        self.elite = []\n",
    "        print('\\nTop performers:')\n",
    "        for no, i in enumerate(elite):\n",
    "            self.elite.append((self.test_results[self.generation]['correct'][i], \n",
    "                               self.population[i]))    \n",
    "            \n",
    "            genome_holder.append(self.genomes[i])\n",
    "            \n",
    "            print(\"{}: score:{}\".format(no, self.test_results[self.generation]['correct'][i]))   \n",
    "            \n",
    "            children.append(self.population[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "        #https://stackoverflow.com/questions/31933784/tournament-selection-in-genetic-algorithm\n",
    "        p = 0.85 # winner probability \n",
    "        tournament_size = 3\n",
    "        probs = [p*((1-p)**i) for i in range(tournament_size-1)]\n",
    "        probs.append(1-np.sum(probs))\n",
    "        #probs = [0.85, 0.1275, 0.0224]\n",
    "        \n",
    "        while len(children) < self.population_sz:\n",
    "            pop = range(len(self.population))\n",
    "            sel_k = random.sample(pop, k=tournament_size)\n",
    "            fitness_k = list(np.array(self.test_results[self.generation]['correct'])[sel_k])\n",
    "            selected = zip(sel_k, fitness_k)\n",
    "            rank = sorted(selected, key=itemgetter(1), reverse=True)\n",
    "            pick = np.random.choice(tournament_size, size=1, p=probs)[0]\n",
    "            best = rank[pick][0]\n",
    "            genome = self.mutate_fn(self.genomes[best], self.layer_space, self.net_space)\n",
    "            print('mutated: ', best)\n",
    "            \n",
    "            genome_holder.append(genome)\n",
    "            model =  self.builder_fn(genome).cuda()\n",
    "            children.append(model)\n",
    "\n",
    "\n",
    "            \n",
    "        self.population = children\n",
    "        self.genomes = genome_holder\n",
    "\n",
    "        \n",
    "        #<----------- add all new genomes to genome history --------->\n",
    "        \n",
    "    def train_nets(self):\n",
    "        \n",
    "        for i, net in enumerate(self.population):\n",
    "            for epoch in range(1, 2):\n",
    "                \n",
    "                torch.manual_seed(1);\n",
    "                \n",
    "                self.train(net, self.dataloader, net.optimizer, epoch)\n",
    "                print('model {} trained'.format(i))\n",
    "                \n",
    "                fp = r\"D:\\Models\\NeuroEvolution/{}-{}\".format(self.generation, i)\n",
    "                torch.save(net.state_dict(), fp)\n",
    "                \n",
    "                \n",
    "                \n",
    "    def evaluate_nets(self):\n",
    "        \"\"\"evaluate the models.\"\"\"\n",
    "        \n",
    "        losses = []\n",
    "        corrects = []\n",
    "        \n",
    "        self.test_results[self.generation] = {}\n",
    "        \n",
    "        for i in range(len(self.population)):\n",
    "            net = self.population[i]\n",
    "            loss, correct = self.test(net, self.adversarials) #CHANGE HERE FOR CLEAN/ADVERSARIAL optimizing\n",
    "            \n",
    "            losses.append(loss)\n",
    "            corrects.append(correct)\n",
    "        \n",
    "        self.test_results[self.generation]['losses'] = losses\n",
    "        self.test_results[self.generation]['correct'] = corrects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = TournamentOptimizer(30, LAYER_SPACE, NET_SPACE, randomize_network, \n",
    "                           mutate_net, NetFromBuildInfo, train, test,\n",
    "                          train_loader, test_loader, adversarial_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 10 trained\n",
      "model 11 trained\n",
      "model 12 trained\n",
      "model 13 trained\n",
      "model 14 trained\n",
      "model 15 trained\n",
      "model 16 trained\n",
      "model 17 trained\n",
      "model 18 trained\n",
      "model 19 trained\n",
      "model 20 trained\n",
      "model 21 trained\n",
      "model 22 trained\n",
      "model 23 trained\n",
      "model 24 trained\n",
      "model 25 trained\n",
      "model 26 trained\n",
      "model 27 trained\n",
      "model 28 trained\n",
      "model 29 trained\n",
      "\n",
      "Population mean:1840.9333333333334 max:2760\n",
      "\n",
      "Top performers:\n",
      "0: score:2760\n",
      "1: score:2505\n",
      "mutated:  3\n",
      "mutated:  27\n",
      "mutated:  4\n",
      "mutated:  3\n",
      "mutated:  4\n",
      "mutated:  29\n",
      "mutated:  21\n",
      "mutated:  19\n",
      "mutated:  18\n",
      "mutated:  29\n",
      "mutated:  7\n",
      "mutated:  11\n",
      "mutated:  25\n",
      "mutated:  15\n",
      "mutated:  10\n",
      "mutated:  15\n",
      "mutated:  16\n",
      "mutated:  29\n",
      "mutated:  17\n",
      "mutated:  3\n",
      "mutated:  23\n",
      "mutated:  0\n",
      "mutated:  21\n",
      "mutated:  29\n",
      "mutated:  19\n",
      "mutated:  12\n",
      "mutated:  20\n",
      "mutated:  29\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    testing.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'correct': [2005,\n",
       "   983,\n",
       "   1800,\n",
       "   1258,\n",
       "   2256,\n",
       "   1265,\n",
       "   1851,\n",
       "   1802,\n",
       "   1232,\n",
       "   1689,\n",
       "   1728,\n",
       "   1028,\n",
       "   502,\n",
       "   1391,\n",
       "   1417,\n",
       "   967,\n",
       "   1954,\n",
       "   1863,\n",
       "   1289,\n",
       "   980,\n",
       "   1336,\n",
       "   1744,\n",
       "   2329,\n",
       "   1471,\n",
       "   958,\n",
       "   1223,\n",
       "   1355,\n",
       "   1153,\n",
       "   1077,\n",
       "   2039],\n",
       "  'losses': [2.278823974609375,\n",
       "   5028.9832,\n",
       "   2.0798281982421876,\n",
       "   4.3766138671875,\n",
       "   2.068897998046875,\n",
       "   3.26730341796875,\n",
       "   2.2750092041015626,\n",
       "   2.5014030517578125,\n",
       "   230.252775,\n",
       "   2.2676238037109373,\n",
       "   2.285697412109375,\n",
       "   8870224.896,\n",
       "   5.26239052734375,\n",
       "   2.6239562255859377,\n",
       "   2.164543896484375,\n",
       "   3.5549892333984374,\n",
       "   147.4544546875,\n",
       "   338.548384375,\n",
       "   2.300280078125,\n",
       "   nan,\n",
       "   2.726551611328125,\n",
       "   4.89104619140625,\n",
       "   7.02229619140625,\n",
       "   2.6457461669921876,\n",
       "   4.1087470703125,\n",
       "   2.436090966796875,\n",
       "   2.4254484619140624,\n",
       "   2.4861462646484376,\n",
       "   6000.79775,\n",
       "   2.2147043701171873]},\n",
       " 2: {'correct': [2009,\n",
       "   2034,\n",
       "   1940,\n",
       "   1697,\n",
       "   1065,\n",
       "   1385,\n",
       "   1915,\n",
       "   1496,\n",
       "   1645,\n",
       "   961,\n",
       "   1951,\n",
       "   1346,\n",
       "   1455,\n",
       "   1676,\n",
       "   958,\n",
       "   2083,\n",
       "   2087,\n",
       "   945,\n",
       "   2226,\n",
       "   1371,\n",
       "   1027,\n",
       "   1321,\n",
       "   1280,\n",
       "   1820,\n",
       "   1938,\n",
       "   1305,\n",
       "   1722,\n",
       "   1001,\n",
       "   1897,\n",
       "   1326],\n",
       "  'losses': [3.54627080078125,\n",
       "   2.057972961425781,\n",
       "   5.97762841796875,\n",
       "   2.40098681640625,\n",
       "   5.39517021484375,\n",
       "   2.2961361328125,\n",
       "   2.221277783203125,\n",
       "   2.3765858642578124,\n",
       "   11.5548416015625,\n",
       "   3.094794677734375,\n",
       "   2.074284729003906,\n",
       "   2.409730810546875,\n",
       "   2.156866015625,\n",
       "   8.204082373046875,\n",
       "   5.4439248046875,\n",
       "   2.210108935546875,\n",
       "   8.172333740234375,\n",
       "   3.2324564453125,\n",
       "   7.478514697265625,\n",
       "   2.5912439697265626,\n",
       "   11170.8927,\n",
       "   2.1606494384765624,\n",
       "   100.683521875,\n",
       "   146.3162671875,\n",
       "   2.2223140625,\n",
       "   2.2254204833984375,\n",
       "   2.50296923828125,\n",
       "   4.779305078125,\n",
       "   4.876099560546875,\n",
       "   2.4245877197265626]},\n",
       " 3: {'correct': [1919,\n",
       "   2319,\n",
       "   958,\n",
       "   1894,\n",
       "   1358,\n",
       "   1210,\n",
       "   1627,\n",
       "   1057,\n",
       "   2104,\n",
       "   1640,\n",
       "   980,\n",
       "   2053,\n",
       "   958,\n",
       "   1776,\n",
       "   1529,\n",
       "   1909,\n",
       "   1822,\n",
       "   1926,\n",
       "   1494,\n",
       "   1730,\n",
       "   2590,\n",
       "   946,\n",
       "   2292,\n",
       "   2542,\n",
       "   1715,\n",
       "   1686,\n",
       "   1453,\n",
       "   1831,\n",
       "   980,\n",
       "   1806],\n",
       "  'losses': [3.222986083984375,\n",
       "   4.0539802734375,\n",
       "   2.548697265625,\n",
       "   4.129394262695312,\n",
       "   2.669371337890625,\n",
       "   2.46682490234375,\n",
       "   6.96600595703125,\n",
       "   7554.42175,\n",
       "   2.21163681640625,\n",
       "   2.104807275390625,\n",
       "   nan,\n",
       "   2.199433837890625,\n",
       "   6.105171728515625,\n",
       "   2.5551626953125,\n",
       "   2.31297900390625,\n",
       "   2.07849345703125,\n",
       "   2.1357996337890626,\n",
       "   4.809207080078125,\n",
       "   173.740340625,\n",
       "   2.4093680908203123,\n",
       "   7.012537744140625,\n",
       "   3.8784407470703126,\n",
       "   2.0836832275390624,\n",
       "   8.12520849609375,\n",
       "   4.076741870117187,\n",
       "   2.358187255859375,\n",
       "   2.4077615234375,\n",
       "   7.355587841796875,\n",
       "   nan,\n",
       "   2.7902637939453125]},\n",
       " 4: {'correct': [1823,\n",
       "   1992,\n",
       "   2011,\n",
       "   1032,\n",
       "   1806,\n",
       "   1874,\n",
       "   1907,\n",
       "   2004,\n",
       "   1858,\n",
       "   2322,\n",
       "   1597,\n",
       "   1871,\n",
       "   2454,\n",
       "   1859,\n",
       "   929,\n",
       "   1630,\n",
       "   1793,\n",
       "   2005,\n",
       "   979,\n",
       "   1924,\n",
       "   1098,\n",
       "   2011,\n",
       "   958,\n",
       "   2572,\n",
       "   2381,\n",
       "   1213,\n",
       "   1541,\n",
       "   2425,\n",
       "   2305,\n",
       "   2527],\n",
       "  'losses': [2.6338515869140626,\n",
       "   4.505665576171875,\n",
       "   4.6969310546875,\n",
       "   2.2941115234375,\n",
       "   2.1901260009765626,\n",
       "   6.53142685546875,\n",
       "   2.422041357421875,\n",
       "   7.146131494140625,\n",
       "   2.427860595703125,\n",
       "   6.603024462890625,\n",
       "   3.5321579345703125,\n",
       "   2.0891597412109375,\n",
       "   2.068804968261719,\n",
       "   2.394473681640625,\n",
       "   8.374692919921875,\n",
       "   2.1594099609375,\n",
       "   2.396337890625,\n",
       "   10.449412890625,\n",
       "   7.99726044921875,\n",
       "   2.0796739990234374,\n",
       "   7.332064892578125,\n",
       "   2.115060107421875,\n",
       "   5.978383935546875,\n",
       "   2.1917452880859374,\n",
       "   8.134157177734375,\n",
       "   2.945855908203125,\n",
       "   2.242148779296875,\n",
       "   8.87206474609375,\n",
       "   2.086467919921875,\n",
       "   7.026108837890625]}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def progressplotter(optimizer):\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rebuild_from_save(optimizer, generation, position):\n",
    "    \n",
    "    genome = optimizer.genome_history[generation][position]\n",
    "    \n",
    "    net = NetFromBuildInfo(genome)\n",
    "    \n",
    "    net.load_state_dict(torch.load(r\"D:\\Models\\NeuroEvolution\\{}-{}\".format(generation, position)))\n",
    "    \n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanity_check(optimizer, test_loader):\n",
    "    \n",
    "    for generation in optimizer.test_results:\n",
    "        print('generation {}: \\n'.format(generation))\n",
    "        for i, result in enumerate(optimizer.test_results[generation]['correct']):\n",
    "            \n",
    "            mod = rebuild_from_save(optimizer, generation, i)\n",
    "            _, rebuild_result = test(mod, test_loader)\n",
    "            \n",
    "            if result == rebuild_result:\n",
    "                print(\"result = {}, rebuild result = {}. (equal)\".format(result, rebuild_result))\n",
    "            else:\n",
    "                print(\"result = {}, rebuild result = {}. (different!!)\".format(result, rebuild_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation 1: \n",
      "\n",
      "result = 1215, rebuild result = 1215. (equal)\n",
      "result = 1822, rebuild result = 1822. (equal)\n",
      "result = 1407, rebuild result = 1407. (equal)\n"
     ]
    }
   ],
   "source": [
    "sanity_check(testing, adversarial_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
