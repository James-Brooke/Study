{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor()])\n",
    "\n",
    "MNIST_train = datasets.MNIST(r'D:\\Data_sets/MNIST', \n",
    "                            train=True, download=True,\n",
    "                            transform=transform)\n",
    "\n",
    "MNIST_test = datasets.MNIST(r'D:\\Data_sets/MNIST', \n",
    "                            train=False, download=True,\n",
    "                            transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                            MNIST_train, batch_size=64, \n",
    "                            shuffle=True, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(MNIST_test,\n",
    "                            batch_size=1000, shuffle=True, \n",
    "                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, adv_func=None, adversarial=False, eps=0.5):\n",
    "    \"\"\"\n",
    "    Test model\n",
    "\n",
    "    Args:\n",
    "    test_loader: a PyTorch dataloader to test on\n",
    "    adv_func: a function that returns adversarial examples \n",
    "    \"\"\"\n",
    "    model.train(False)\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if adversarial:\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda().double(), target.cuda()\n",
    "            data= adv_func(model, data, target, eps=eps)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred).cuda()).sum().item()\n",
    "            test_loss += criterion(output, target).item()\n",
    "        \n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                output = model(data)\n",
    "                test_loss += criterion(output, target).item()\n",
    "                pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    \n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(test_loader))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        #self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(x, chance, mean, std):\n",
    "    if np.random.rand() > (1-chance): \n",
    "        x = np.random.normal(loc=mean, scale=std)\n",
    "        return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(params, chance):\n",
    "    mean = params.detach().mean()\n",
    "    std = params.detach().std()\n",
    "    return params.detach().apply_(lambda x: mutate(x, chance, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_weights(model, chance):\n",
    "    model.cpu()\n",
    "    params = list(model.parameters())\n",
    "    for param in params:\n",
    "        if len(param.shape) == 1:\n",
    "            param.data = update_weights(param, chance)\n",
    "        elif len(param.shape) == 2:\n",
    "            for inner_param in param:\n",
    "                    inner_param.data = update_weights(inner_param, chance)\n",
    "        else:\n",
    "            for inner_param in param:\n",
    "                for last_channel in inner_param:\n",
    "                    last_channel.data = update_weights(last_channel, chance)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNet(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(model1, model2):\n",
    "    \n",
    "    mod1 = copy.deepcopy(model1)\n",
    "    mod2 = copy.deepcopy(model2)\n",
    "    \n",
    "    model1_params = list(mod1.parameters())\n",
    "    model2_params = list(mod2.parameters())\n",
    "    \n",
    "    for i, param in enumerate(model1_params):\n",
    "        if len(param.shape) == 1:\n",
    "            split = int(np.random.uniform(low=0, high=param.shape[0]))\n",
    "            first_half = param.view(-1)[:split].data \n",
    "            second_half = model2_params[i].view(-1)[split:].data\n",
    "            comb = torch.cat((first_half, second_half)).view_as(param)\n",
    "            first_half = param.view(-1)[split:].data\n",
    "            second_half = model2_params[i].view(-1)[:split].data\n",
    "            comb2 = torch.cat((first_half, second_half)).view_as(param)\n",
    "            param.data = comb\n",
    "            model2_params[i].data = comb2\n",
    "        \n",
    "        elif len(param.shape) == 2:\n",
    "             for j, inner_param in enumerate(param):\n",
    "                split = int(np.random.uniform(low=0, high=inner_param.shape[0]))\n",
    "                first_half = inner_param.view(-1)[:split].data \n",
    "                second_half = model2_params[i][j].view(-1)[split:].data\n",
    "                comb = torch.cat((first_half, second_half)).view_as(inner_param)\n",
    "                first_half = inner_param.view(-1)[split:].data\n",
    "                second_half = model2_params[i][j].view(-1)[:split].data\n",
    "                comb2 = torch.cat((first_half, second_half)).view_as(inner_param)\n",
    "                inner_param.data = comb\n",
    "                model2_params[i][j].data = comb2\n",
    "\n",
    "        else:\n",
    "            for j, inner_param in enumerate(param):\n",
    "                for k, last_channel in enumerate(inner_param):\n",
    "                    split = int(np.random.uniform(low=0, \n",
    "                                high=last_channel.shape[0] * last_channel.shape[1]))\n",
    "                    first_half = last_channel.view(-1)[:split].data \n",
    "                    second_half = model2_params[i][j][k].view(-1)[split:].data\n",
    "                    comb = torch.cat((first_half, second_half)).view_as(last_channel)\n",
    "                    first_half = last_channel.view(-1)[split:].data\n",
    "                    second_half = model2_params[i][j][k].view(-1)[:split].data\n",
    "                    comb2 = torch.cat((first_half, second_half)).view_as(last_channel)\n",
    "                    last_channel.data = comb\n",
    "                    model2_params[i][j][k].data = comb2\n",
    "                    \n",
    "        return mod1, mod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticWeightOptimizer:\n",
    "\n",
    "    def __init__(self, population_sz, test_fn, test_loader, adv_func, RUN):\n",
    "        \n",
    "        self.test = test_fn\n",
    "        self.testloader = test_loader\n",
    "        self.population_sz = population_sz\n",
    "        self.adv_func = adv_func\n",
    "        self.run = RUN\n",
    "        \n",
    "        torch.manual_seed(1)\n",
    "        \n",
    "        self.population = [NNet().cuda() for i in range(self.population_sz)]\n",
    "\n",
    "        self.test_results = {} \n",
    "        self.generation = 0\n",
    "\n",
    "    def step(self, generations=1, save=False, phone=False):\n",
    "\n",
    "        for _ in tnrange(generations, desc='Overall progress'): #tqdm progress bar\n",
    "\n",
    "            self.generation += 1\n",
    "            self.children = []\n",
    "            \n",
    "            self.evaluate_nets()\n",
    "\n",
    "            mean = np.mean(self.test_results[self.generation]['correct'])\n",
    "            best = np.max(self.test_results[self.generation]['correct'])\n",
    "\n",
    "            tqdm.write('Generation {} Population mean:{} max:{}'\n",
    "                       .format(self.generation, mean, best))\n",
    "\n",
    "\n",
    "            n_elite = 2\n",
    "            sorted_pop = np.argsort(self.test_results[self.generation]['correct'])[::-1]\n",
    "            elite = sorted_pop[:n_elite]\n",
    "            \n",
    "            # elites always included in the next population\n",
    "            self.elite = []\n",
    "            print('\\nTop performers:')\n",
    "            for no, i in enumerate(elite):\n",
    "                self.elite.append((self.test_results[self.generation]['correct'][i], \n",
    "                                   self.population[i]))    \n",
    "\n",
    "                self.children.append(self.population[i])\n",
    "\n",
    "                tqdm.write(\"{}: score:{}\".format(no,\n",
    "                            self.test_results[self.generation]['correct'][i]))   \n",
    "\n",
    "\n",
    "            #https://stackoverflow.com/questions/31933784/tournament-selection-in-genetic-algorithm\n",
    "            p = 0.85 # winner probability \n",
    "            tournament_size = 5\n",
    "            probs = [p*((1-p)**i) for i in range(tournament_size-1)]\n",
    "            probs.append(1-np.sum(probs))\n",
    "            #probs = [0.85, 0.1275, 0.0224,  0.01913, 0.00286, 0.000506]\n",
    "\n",
    "            while len(self.children) < self.population_sz:\n",
    "                pop = range(len([i for i in range(self.population_sz)]))\n",
    "                sel_k = random.sample(pop, k=5)\n",
    "                fitness_k = list(np.array(self.test_results[self.generation]['correct'])[sel_k] *\n",
    "                                 np.array(self.test_results[self.generation]['clean_correct'])[sel_k])\n",
    "                selected = zip(sel_k, fitness_k)\n",
    "                rank = sorted(selected, key=itemgetter(1), reverse=True)\n",
    "                picks = np.random.choice(tournament_size, size=2, p=probs, replace=False)\n",
    "                parent1 = rank[picks[0]]\n",
    "                parent2 = rank[picks[1]]\n",
    "                bestmodel1 = self.population[parent1[0]]\n",
    "                bestmodel2 = self.population[parent2[0]]\n",
    "                child1, child2 = crossover(bestmodel1, bestmodel2)\n",
    "                mutate_weights(child1, 0.01)\n",
    "                mutate_weights(child2, 0.01)\n",
    "                self.children.append(child1)\n",
    "                self.children.append(child2)\n",
    "                \n",
    "            self.population = self.children\n",
    "            \n",
    "    def evaluate_nets(self):\n",
    "        \"\"\"evaluate the models.\"\"\"\n",
    "\n",
    "        losses = []\n",
    "        corrects = []\n",
    "        clean_corrects = []\n",
    "\n",
    "        self.test_results[self.generation] = {}\n",
    "\n",
    "        for i in range(len(self.population)):\n",
    "            net = self.population[i]\n",
    "            loss, correct = self.test(net, self.testloader, adv_func=self.adv_func,\n",
    "                                    adversarial=False, eps=0.5) #Return to adversarial later\n",
    "            _, clean_correct = self.test(net, self.testloader)\n",
    "\n",
    "            corrects.append(correct)\n",
    "            clean_corrects.append(clean_correct)\n",
    "\n",
    "        self.test_results[self.generation]['correct'] = corrects\n",
    "        self.test_results[self.generation]['clean_correct'] = clean_corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = GeneticWeightOptimizer(5, test, test_loader, None, RUN=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db34eb54bb34e409f4cd1a25689b4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Overall progress', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 Population mean:990.0 max:1135\n",
      "\n",
      "Top performers:\n",
      "0: score:1135\n",
      "1: score:1032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'clean_correct': [1135, 924, 1032, 985, 874],\n",
       "  'correct': [1135, 924, 1032, 985, 874]}}"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 30)"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = range(len([i for i in range(30)]))\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 21, 11, 26, 0]"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_k = random.sample(pop, k=5)\n",
    "sel_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94532614, 0.28970304, 0.10988849, 0.29124922, 0.64319062])"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness_k = np.array([random.random() for j in range(30)])[sel_k]\n",
    "fitness_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = zip(sel_k, fitness_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 0.9453261385813639),\n",
       " (0, 0.6431906235929987),\n",
       " (26, 0.2912492188679531),\n",
       " (21, 0.2897030386684928),\n",
       " (11, 0.10988848594747402)]"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = sorted(selected, key=itemgetter(1), reverse=True)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picks = np.random.choice(5, size=2, p=probs, replace=False)\n",
    "picks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 0.9453261385813639)"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best1 = rank[picks[0]]\n",
    "best1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.6431906235929987)"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best2 = rank[picks[1]]\n",
    "best2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = range(len([i for i in range(30)]))\n",
    "sel_k = random.sample(pop, k=5)\n",
    "fitness_k = list(np.array(self.test_results[self.generation]['correct'])[sel_k] *\n",
    "                 np.array(self.test_results[self.generation]['clean_correct'])[sel_k])\n",
    "selected = zip(sel_k, fitness_k)\n",
    "rank = sorted(selected, key=itemgetter(1), reverse=True)\n",
    "picks = np.random.choice(tournament_size, size=2, p=probs, replace=False)\n",
    "parent1 = rank[picks[0]]\n",
    "parent2 = rank[picks[1]]\n",
    "bestmodel1 = population[parent1[0]]\n",
    "bestmodel2 = population[parent2[0]]\n",
    "child1, child2 = crossover(bestmodel1, bestmodel2)\n",
    "mutate_weights(child1, 0.01)\n",
    "mutate_weights(child2, 0.01)\n",
    "self.children.append(child1)\n",
    "self.children.append(child2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
