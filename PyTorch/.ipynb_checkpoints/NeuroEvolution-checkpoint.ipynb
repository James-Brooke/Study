{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "812f6499-b123-431b-b1d1-9b5c1abfb867"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "27f4dcd0-5f3f-4e82-b356-09a456044181"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import requests #for sending updates to my phone via telegram\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "d5ecc517-1d29-46db-8b0e-bd05b7fcc8d2"
    }
   },
   "outputs": [],
   "source": [
    "with open(r\"D:\\TELEGRAM_BOTS\\NEURALUPDATES.txt\") as file: #Credentials for telegram bot\n",
    "    BOT_TOKEN, CHANNEL = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "nbpresent": {
     "id": "8c49b785-f670-4b52-a992-7c7da9f01826"
    }
   },
   "source": [
    "## Bokeh and interactive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "e19a5758-107a-4843-8ddc-8d13464d3a6a"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets  import interactive\n",
    "from bokeh.plotting import figure \n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool, WheelZoomTool\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "output_notebook()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "6ab5b3b4-9112-46f0-96dd-3602d11eb80b"
    }
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "nbpresent": {
     "id": "11d4c2cc-47ed-412e-994e-bb19266a3596"
    }
   },
   "source": [
    "## Clean MNIST loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "d4374220-7ffd-4e96-a869-8b04f3d02f11"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "738d6cda-cd66-4028-bd25-f966803e2b67"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),#normalise to range -1 to 1\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,)) #normalise pixels using mean and stdev\n",
    "                       #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                   ])\n",
    "\n",
    "\n",
    "\n",
    "MNIST_train = datasets.MNIST(r'D:\\Data_sets/MNIST', train=True, download=True,\n",
    "                   transform=transform)\n",
    "\n",
    "MNIST_test = datasets.MNIST(r'D:\\Data_sets/MNIST', train=False, download=True,\n",
    "                   transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "4e7135f5-4b31-4ac0-99a5-ceabd508db14"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(MNIST_train, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(MNIST_test,\n",
    "                                          batch_size=1000, \n",
    "                                          shuffle=True, \n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "nbpresent": {
     "id": "31752e42-7a7f-485e-aa07-60cb03e2648c"
    }
   },
   "source": [
    "## Adversarial loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "1ffc8f00-205f-41a5-ab4b-6412eccea568"
    }
   },
   "outputs": [],
   "source": [
    "class AdversarialDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"FGSM adversarials of MNIST test set\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "\n",
    "        self.adversarials = np.load(root_dir+'/adversarials.npy')\n",
    "        self.labels = np.load(root_dir+'/labels.npy')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.adversarials[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "fc86c210-6aa3-4eee-bd79-2db6f19cdb62"
    }
   },
   "outputs": [],
   "source": [
    "adversarials = AdversarialDataset('D:/Data_sets/Adversarial/MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "4ce7d5e3-7d6d-4619-9035-ee79024a5797"
    }
   },
   "outputs": [],
   "source": [
    "adversarial_loader = torch.utils.data.DataLoader(adversarials, \n",
    "                                           batch_size=1000, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "ed014e8e-f675-46c3-a64e-48fbad0d61f4"
    }
   },
   "source": [
    "# Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "b8994adc-5b7f-4088-8713-927411e0deeb"
    }
   },
   "outputs": [],
   "source": [
    "LAYER_SPACE = {\n",
    "    'nb_units':{'lb': 128, 'ub':2048, 'mutate': 0.15},\n",
    "    'dropout_rate': {'lb': 0.0, 'ub': 0.7, 'mutate': 0.2},\n",
    "    'activation': {'func': ['linear','tanh','relu','sigmoid','elu'], 'mutate':0.2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "528be303-7e62-4fcf-b80f-6965df7a2329"
    }
   },
   "outputs": [],
   "source": [
    "NET_SPACE = {\n",
    "    'nb_layers': {'lb': 1, 'ub': 3, 'mutate': 0.15},\n",
    "    'lr': {'lb': 0.001, 'ub':0.1, 'mutate': 0.15},\n",
    "    'weight_decay': {'lb': 0.00001, 'ub': 0.0004, 'mutate':0.2},\n",
    "    'optimizer': {'func': ['sgd', 'adam', 'adadelta','rmsprop'], 'mutate': 0.2}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "1202ab00-480c-4cea-bad7-56143cf3fd94"
    }
   },
   "source": [
    "# Randomise network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "91512676-c536-4b0f-8fb2-3cc0763d48c8"
    }
   },
   "outputs": [],
   "source": [
    "def random_value(space):\n",
    "    \"\"\"Returns random value from space.\"\"\"\n",
    "    \n",
    "    val = None\n",
    "    \n",
    "    if 'func' in space: #randomise optimiser or activation function\n",
    "        val = random.sample(space['func'], 1)[0] \n",
    "    \n",
    "    elif isinstance(space['lb'], int): #randomise number of units or layers\n",
    "        val = random.randint(space['lb'], space['ub'])\n",
    "    \n",
    "    else: #randomise percentages, i.e. dropout rates or weight decay\n",
    "        val = random.random() * (space['ub'] - space['lb']) + space['lb']\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "56543a23-5a03-4263-881d-f58f251341bc"
    }
   },
   "outputs": [],
   "source": [
    "def randomize_network(layer_space, net_space): \n",
    "    \"\"\"Returns a randomised neural network\"\"\"\n",
    "    net = {}\n",
    "    \n",
    "    for key in net_space.keys():\n",
    "        net[key] = random_value(net_space[key])\n",
    "        \n",
    "    layers = []\n",
    "    \n",
    "    for i in range(net['nb_layers']):\n",
    "        layer = {}\n",
    "        for key in layer_space.keys():\n",
    "            layer[key] = random_value(layer_space[key])\n",
    "        layers.append(layer)\n",
    "        net['layers'] = layers\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "0728eff2-6f69-4b57-bbbb-22f6ef8c6bb2"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randomize_network(LAYER_SPACE, NET_SPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "7237d712-7220-4057-976e-db2ea32fb277"
    }
   },
   "source": [
    "# Mutate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "4155d9ac-95b8-4bf4-beae-ad82771a69eb"
    }
   },
   "outputs": [],
   "source": [
    "def mutate_net(nnet, layer_space, net_space):\n",
    "    \n",
    "    net = copy.deepcopy(nnet)\n",
    "    \n",
    "    \n",
    "    # mutate optimizer\n",
    "    for k in ['lr', 'weight_decay', 'optimizer']:\n",
    "        if random.random() < net_space[k]['mutate']:\n",
    "            net[k] = random_value(net_space[k])\n",
    "    \n",
    "    \n",
    "    # mutate layers\n",
    "    for layer in net['layers']:\n",
    "        for k in layer_space.keys():\n",
    "            if random.random() < layer_space[k]['mutate']:\n",
    "                layer[k] = random_value(layer_space[k])\n",
    "                \n",
    "                \n",
    "    # mutate number of layers -- 50% add 50% remove\n",
    "    if random.random() < net_space['nb_layers']['mutate']:\n",
    "        if net['nb_layers'] <= net_space['nb_layers']['ub']:\n",
    "            if random.random()< 0.5 and \\\n",
    "            net['nb_layers'] < net_space['nb_layers']['ub']:\n",
    "                layer = {}\n",
    "                for key in layer_space.keys():\n",
    "                    layer[key] = random_value(layer_space[key])\n",
    "                net['layers'].append(layer)      \n",
    "            else:\n",
    "                if net['nb_layers'] > 1:\n",
    "                    net['layers'].pop()\n",
    "\n",
    "                \n",
    "            # value & id update\n",
    "            net['nb_layers'] = len(net['layers'])         \n",
    "            \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "3880b8b5-95b9-49a9-833f-3ed1fd1f6502"
    }
   },
   "source": [
    "# NetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "a55b4b88-a3fc-454e-b2b7-3a1d464b5bcd"
    }
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \"\"\"Flattens input to vector size (batchsize, 1)\n",
    "    (for use in NetFromBuildInfo).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "0400b4a6-67da-42ce-a770-5c0112031eb3"
    }
   },
   "outputs": [],
   "source": [
    "class NetFromBuildInfo(nn.Module):\n",
    "    def __init__(self, build_info):\n",
    "        super(NetFromBuildInfo, self).__init__()\n",
    "        \n",
    "        self.activation_dict = {\n",
    "            'tanh': nn.Tanh(),\n",
    "            'relu': nn.ReLU(),\n",
    "            'sigmoid': nn.Sigmoid(),\n",
    "            'elu': nn.ELU()\n",
    "            }\n",
    "\n",
    "        #NETWORK DEFINITION\n",
    "        \n",
    "        previous_units = 28 * 28 #MNIST shape\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module('flatten', Flatten())\n",
    "         \n",
    "        for i, layer_info in enumerate(build_info['layers']):\n",
    "            i = str(i)\n",
    "            \n",
    "            self.model.add_module(\n",
    "                'fc_' + i,\n",
    "                nn.Linear(previous_units, layer_info['nb_units'])\n",
    "                )\n",
    "            \n",
    "            previous_units = layer_info['nb_units']\n",
    "            \n",
    "            self.model.add_module(\n",
    "                'dropout_' + i,\n",
    "                nn.Dropout(p=layer_info['dropout_rate'])\n",
    "                )\n",
    "            if layer_info['activation'] == 'linear':\n",
    "                continue #linear activation is identity function\n",
    "            self.model.add_module(\n",
    "                layer_info['activation']+ i,\n",
    "                self.activation_dict[layer_info['activation']])\n",
    "\n",
    "        self.model.add_module(\n",
    "            'logits',\n",
    "            nn.Linear(previous_units, 10) #10 MNIST classes\n",
    "            )\n",
    "        \n",
    "        \n",
    "        ##OPTIMIZER\n",
    "\n",
    "        self.opt_args = {#'params': self.model.parameters(),\n",
    "                 'weight_decay': build_info['weight_decay'],\n",
    "                 'lr': build_info['lr']\n",
    "                 }\n",
    "        \n",
    "        self.optimizer_dict = {\n",
    "            'adam': optim.Adam(self.model.parameters(),**self.opt_args),\n",
    "            'rmsprop': optim.RMSprop(self.model.parameters(),**self.opt_args),\n",
    "            'adadelta':optim.Adadelta(self.model.parameters(),**self.opt_args),\n",
    "            'sgd': optim.SGD(self.model.parameters(), **self.opt_args, momentum=0.9) #momentum to train faster\n",
    "            }\n",
    "\n",
    "        self.optimizer = self.optimizer_dict[build_info['optimizer']]\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "10ff2c42-a5e8-47ac-9499-81802c7e9c97"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "991d7e5a-86cf-4ba9-9240-89389382e486"
    }
   },
   "source": [
    "# Train test helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "71bc80c5-0aa0-4753-9082-7d749713dbf3"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss /= len(train_loader.dataset)    \n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Train Epoch: {} \\t Loss: {:.6f}'.format(epoch, running_loss ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "3813f516-39bf-413a-aa8b-1bfd04193110"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, adversarial=False, eps=0.5):\n",
    "    \n",
    "    model.train(False)\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    if adversarial:\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            data= fgsm(model, data, target, eps=eps)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred).cuda()).sum().item()\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        \n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                output = model(data)\n",
    "                test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "                pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    \n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "a4e99450-5bb7-44cd-947a-fed2270d8082"
    }
   },
   "source": [
    "# FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "c29af907-1fc3-4ac9-b56e-247d20669dcb"
    }
   },
   "outputs": [],
   "source": [
    "grads = {} #closure for use as a hook in fgsm attack - otherwise gradients can't be obtained for images. \n",
    "def save_grad(name):\n",
    "    def hook(grad):\n",
    "        grads[name] = grad\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "9c713ba3-e84b-4960-b461-e405e9a9b746"
    }
   },
   "outputs": [],
   "source": [
    "def fgsm(model, x, y, eps=0.3, x_val_min=0, x_val_max=1, batch=True): #https://arxiv.org/pdf/1412.6572.pdf\n",
    "    \n",
    "    x_adv = Variable(x.data, requires_grad=True).cuda() #clean image\n",
    "    x_adv.register_hook(save_grad('x_adv'))\n",
    "\n",
    "    h_adv = model(x_adv) #clean pred\n",
    "    \n",
    "    cost = F.nll_loss(h_adv, y.cuda()) #negative log loss clean image and clean pred\n",
    "\n",
    "    if x_adv.grad is not None:\n",
    "        x_adv.grad.data.fill_(0)\n",
    "\n",
    "    cost.backward()\n",
    "\n",
    "    #x_adv.grad.sign_() #take sign of gradients \n",
    "    x_adv = x_adv + (eps*grads['x_adv'].sign())\n",
    "    x_adv = torch.clamp(x_adv, x_val_min, x_val_max)\n",
    "    \n",
    "    if batch == False:\n",
    "        with torch.no_grad():\n",
    "            h = model(x)\n",
    "            h_adv = model(x_adv)\n",
    "\n",
    "        return x_adv, h_adv, h\n",
    "    \n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e60a8246-bc55-48c2-9e73-95ef413157ee"
    }
   },
   "source": [
    "# Evolution optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a565f55d-07c3-4d38-9c33-9689d39d5713"
    }
   },
   "outputs": [],
   "source": [
    "class TournamentOptimizer:\n",
    "    \"\"\"Define a tournament play selection process.\"\"\"\n",
    "\n",
    "    def __init__(self, population_sz, layer_space, net_space, init_fn, mutate_fn, builder_fn,\n",
    "                 train_fn, test_fn, data_loader, test_loader, adversarial_loader):\n",
    "        \n",
    "        self.init_fn = init_fn\n",
    "        self.layer_space = layer_space\n",
    "        self.net_space = net_space\n",
    "        self.mutate_fn = mutate_fn\n",
    "        self.builder_fn = builder_fn\n",
    "        self.train = train_fn\n",
    "        self.test = test_fn\n",
    "        self.dataloader = data_loader\n",
    "        self.testloader = test_loader\n",
    "        self.population_sz = population_sz\n",
    "        self.adversarials = adversarial_loader\n",
    "        \n",
    "        torch.manual_seed(1);\n",
    "        \n",
    "        self.genomes = [init_fn(self.layer_space, self.net_space) for i in range(population_sz)]   \n",
    "        self.population = []\n",
    "        \n",
    "        self.test_results = {} \n",
    "        self.genome_history = {} \n",
    "\n",
    "        self.generation = 0\n",
    "\n",
    "    def step(self, generations=1, save=True, phone=False):\n",
    "        \"\"\"Tournament evolution step.\"\"\"\n",
    "\n",
    "        for _ in tnrange(generations, desc='Overall progress'): #tqdm progress bar\n",
    "\n",
    "            self.generation += 1\n",
    "\n",
    "            self.genome_history[self.generation] = self.genomes\n",
    "            self.population = [NetFromBuildInfo(i).cuda() for i in self.genomes]\n",
    "            self.children = []\n",
    "            \n",
    "\n",
    "            self.train_nets(save=save)\n",
    "            self.evaluate_nets()\n",
    "\n",
    "            mean = np.mean(self.test_results[self.generation]['correct'])\n",
    "            best = np.max(self.test_results[self.generation]['correct'])\n",
    "\n",
    "            tqdm.write('Generation {} Population mean:{} max:{}'\n",
    "                       .format(self.generation, mean, best))\n",
    "            \n",
    "            if phone: #update via telegram\n",
    "                requests.post(\"https://api.telegram.org/bot{}/\"\n",
    "                  \"sendMessage\".format(BOT_TOKEN), \n",
    "                  data={'chat_id': '{}'.format(CHANNEL),\n",
    "                    'text':'Generation {} completed \\n'\n",
    "                        'Population mean: {} max: {}'\n",
    "                        .format(self.generation, mean, best)})\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "            n_elite = 2\n",
    "            sorted_pop = np.argsort(self.test_results[self.generation]['correct'])[::-1]\n",
    "            elite = sorted_pop[:n_elite]\n",
    "            \n",
    "            # elites always included in the next population\n",
    "            self.elite = []\n",
    "            print('\\nTop performers:')\n",
    "            for no, i in enumerate(elite):\n",
    "                self.elite.append((self.test_results[self.generation]['correct'][i], \n",
    "                                   self.population[i]))    \n",
    "\n",
    "                self.children.append(self.genomes[i])\n",
    "\n",
    "                tqdm.write(\"{}: score:{}\".format(no,\n",
    "                            self.test_results[self.generation]['correct'][i]))   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #https://stackoverflow.com/questions/31933784/tournament-selection-in-genetic-algorithm\n",
    "            p = 0.85 # winner probability \n",
    "            tournament_size = 3\n",
    "            probs = [p*((1-p)**i) for i in range(tournament_size-1)]\n",
    "            probs.append(1-np.sum(probs))\n",
    "            #probs = [0.85, 0.1275, 0.0224]\n",
    "\n",
    "            while len(self.children) < self.population_sz:\n",
    "                pop = range(len(self.population))\n",
    "                sel_k = random.sample(pop, k=tournament_size)\n",
    "                fitness_k = list(np.array(self.test_results[self.generation]['correct'])[sel_k])\n",
    "                selected = zip(sel_k, fitness_k)\n",
    "                rank = sorted(selected, key=itemgetter(1), reverse=True)\n",
    "                pick = np.random.choice(tournament_size, size=1, p=probs)[0]\n",
    "                best = rank[pick][0]\n",
    "                genome = self.mutate_fn(self.genomes[best], self.layer_space, self.net_space)\n",
    "                self.children.append(genome)\n",
    "                \n",
    "            self.genomes = self.children\n",
    "                \n",
    "\n",
    "        \n",
    "        \n",
    "    def train_nets(self, save=True):\n",
    "        \"\"\"trains population of nets\"\"\"\n",
    "         \n",
    "        for i, net in enumerate(tqdm_notebook(self.population)):\n",
    "            for epoch in range(1, 5):\n",
    "                torch.manual_seed(1);\n",
    "                self.train(net, self.dataloader, net.optimizer, epoch)\n",
    "                \n",
    "            if save:\n",
    "                fp = r\"D:\\Models\\NeuroEvolution/{}-{}\".format(self.generation, i)\n",
    "                torch.save(net.state_dict(), fp)\n",
    "                \n",
    "                \n",
    "    def evaluate_nets(self):\n",
    "        \"\"\"evaluate the models.\"\"\"\n",
    "        \n",
    "        losses = []\n",
    "        corrects = []\n",
    "        clean_corrects = []\n",
    "        \n",
    "        self.test_results[self.generation] = {}\n",
    "        \n",
    "        for i in range(len(self.population)):\n",
    "            net = self.population[i]\n",
    "            loss, correct = self.test(net, self.testloader, adversarial=True, eps=0.5) \n",
    "            _, clean_correct = self.test(net, self.testloader)\n",
    "            \n",
    "            losses.append(loss)\n",
    "            corrects.append(correct)\n",
    "            clean_corrects.append(clean_correct)\n",
    "        \n",
    "        self.test_results[self.generation]['losses'] = losses\n",
    "        self.test_results[self.generation]['correct'] = corrects\n",
    "        self.test_results[self.generation]['clean_correct'] = clean_corrects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "860bfaf2-cae6-4398-9a0f-917a7150cf78"
    }
   },
   "source": [
    "# Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c2d1cca7-525a-421a-b697-a9bdfdbda28c"
    }
   },
   "outputs": [],
   "source": [
    "testing2 = TournamentOptimizer(30, LAYER_SPACE, NET_SPACE, randomize_network, \n",
    "                           mutate_net, NetFromBuildInfo, train, test,\n",
    "                          train_loader, test_loader, adversarial_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7c458a79-8641-4582-b036-bc4f4860ea12"
    }
   },
   "outputs": [],
   "source": [
    "testing2.step(generations=50, save=True, phone=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "5d408b65-ba0a-4dbe-82e7-651a90822c55"
    }
   },
   "source": [
    "# Progress plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "nbpresent": {
     "id": "eaae8958-ca22-4cf2-8d5f-027197747c00"
    }
   },
   "source": [
    "## Plot func definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "c4a9ff28-94ed-43ff-b7fb-23d9c372c0c5"
    }
   },
   "outputs": [],
   "source": [
    "def progressplotter(optimizer, clean=False):\n",
    "    \n",
    "    if clean:\n",
    "        dataset = 'clean_correct'\n",
    "    else:\n",
    "        dataset = 'correct'\n",
    "    \n",
    "    means = []\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    gens = range(len(optimizer.test_results))\n",
    "    popsize = len(optimizer.test_results[1][dataset])\n",
    "    \n",
    "    for i in gens:\n",
    "        ax.scatter([i for j in range(popsize)], optimizer.test_results[i+1][dataset])\n",
    "        mean = np.mean(optimizer.test_results[i+1][dataset])\n",
    "        means.append(mean)\n",
    "        ax.scatter(i, mean, c=1)\n",
    "        \n",
    "        if i == 0:\n",
    "            continue\n",
    "        plt.plot([i-1, i], [means[i-1], mean], c='black')\n",
    "        \n",
    "    ax.set_xticks(np.arange(0, len(means),1))\n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Correct classifications')\n",
    "    \n",
    "    if clean:\n",
    "        ax.set_title('Accuracy on clean dataset')\n",
    "    else:\n",
    "        ax.set_title('Accuracy on adversarial dataset')\n",
    "    \n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label]):\n",
    "        item.set_fontsize(30)\n",
    "        \n",
    "    for item in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "ba0972b4-579d-4bf2-b5a8-e6f123d64c7f"
    }
   },
   "outputs": [],
   "source": [
    "def diffplotter(optimizer):\n",
    "    diff = {}\n",
    "    for gen in optimizer.test_results:\n",
    "        diff[gen] = []\n",
    "        for i in range(len(optimizer.test_results[gen]['clean_correct'])):\n",
    "            clean = optimizer.test_results[gen]['clean_correct'][i]\n",
    "            adver = optimizer.test_results[gen]['correct'][i]\n",
    "            diff[gen].append(clean - adver)\n",
    "            \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    gens = len(optimizer.test_results)\n",
    "    popsize = len(optimizer.test_results[gen]['clean_correct'])\n",
    "\n",
    "    for i in range(gens):\n",
    "        ax.scatter([i for j in range(popsize)], diff[i+1])\n",
    "        \n",
    "    ax.set_title('Difference between clean and adversarial accuracy')\n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Clean accuracy - adversarial accuracy')\n",
    "    \n",
    "    ax.set_xticks(np.arange(0, gens,1))\n",
    "    \n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label]):\n",
    "        item.set_fontsize(30)\n",
    "        \n",
    "    for item in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "11a2595a-3611-489d-b81d-3d4a6dd3526c"
    }
   },
   "outputs": [],
   "source": [
    "def bestplotter(optimizer, k=0):\n",
    "\n",
    "    holder = {\n",
    "        'clean accuracy' : [],\n",
    "        'adversarial accuracy' : [],\n",
    "        'number of layers' : [],\n",
    "        'activation function' : [],\n",
    "        'dropout rate' : [],\n",
    "        'optimizer' : [],\n",
    "        'number of units in layer' : [],\n",
    "        'learning rate' : [],\n",
    "    }\n",
    "\n",
    "    for gen in optimizer.test_results:\n",
    "\n",
    "        curr = optimizer.test_results[gen]\n",
    "\n",
    "        best_index = np.argsort(curr['correct'])[::-1][k]\n",
    "\n",
    "        holder['clean accuracy'].append(curr['clean_correct'][best_index])\n",
    "        holder['adversarial accuracy'].append(curr['correct'][best_index])\n",
    "\n",
    "        genome = optimizer.genome_history[gen][best_index]\n",
    "\n",
    "        holder['number of layers'].append(genome['nb_layers'])\n",
    "        holder['dropout rate'].append(genome['layers'][0]['dropout_rate'])\n",
    "        holder['number of units in layer'].append(genome['layers'][0]['nb_units'])\n",
    "        holder['optimizer'].append(genome['optimizer'])\n",
    "        holder['activation function'].append(genome['layers'][0]['activation'])\n",
    "        holder['learning rate'].append(genome['lr'])\n",
    "        \n",
    "    gens = len(holder['clean accuracy'])\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    \n",
    "    for i in range(8):\n",
    "        ax = fig.add_subplot(4,2, i+1)\n",
    "        ax.set_ylabel(list(holder.keys())[i])\n",
    "        ax.set_xlabel('Generation')\n",
    "        ax.set_xticks(np.arange(0, gens,5))\n",
    "        ax.yaxis.label.set_fontsize(15)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for j in range(gens):\n",
    "            ax.scatter(j, holder[list(holder.keys())[i]][j], c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "26043f70-613e-420c-a9c7-1f13a63a0301"
    }
   },
   "outputs": [],
   "source": [
    "def avgplotter(optimizer):\n",
    "\n",
    "    holder = {\n",
    "        'clean accuracy' : [],\n",
    "        'adversarial accuracy' : [],\n",
    "        'number of layers' : [],\n",
    "        'activation function' : [],\n",
    "        'dropout rate' : [],\n",
    "        'optimizer' : [],\n",
    "        'number of units in layer' : [],\n",
    "        'learning rate' : [],\n",
    "    }\n",
    "\n",
    "    for gen in optimizer.test_results:\n",
    "\n",
    "        curr = optimizer.test_results[gen]\n",
    "        genomes = optimizer.genome_history[gen]\n",
    "        \n",
    "        templist1 = []\n",
    "        templist2 = []\n",
    "        templist3 = []\n",
    "        templist4 = []\n",
    "        templist5 = []\n",
    "        templist6 = []\n",
    "        for net in genomes:\n",
    "            templist1.append(net['nb_layers'])\n",
    "            templist2.append(net['optimizer'])\n",
    "            templist3.append(net['lr'])\n",
    "            templist4.append(net['layers'][0]['dropout_rate'])\n",
    "            templist5.append(net['layers'][0]['nb_units'])\n",
    "            templist6.append(net['layers'][0]['activation'])\n",
    "            \n",
    "            \n",
    "        holder['number of layers'].append(np.mean(templist1))\n",
    "        holder['optimizer'].append(Counter(templist2).most_common()[0][0])\n",
    "        holder['learning rate'].append(np.mean(templist3))\n",
    "        holder['dropout rate'].append(np.mean(templist4))\n",
    "        holder['number of units in layer'].append(np.mean(templist5))\n",
    "        holder['activation function'].append(Counter(templist6).most_common()[0][0])\n",
    "        \n",
    "\n",
    "        holder['clean accuracy'].append(np.mean(curr['clean_correct']))\n",
    "        holder['adversarial accuracy'].append(np.mean(curr['correct']))\n",
    "            \n",
    "\n",
    "    gens = len(holder['clean accuracy'])\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    \n",
    "    for i in range(8):\n",
    "        ax = fig.add_subplot(4,2, i+1)\n",
    "        ax.set_ylabel(list(holder.keys())[i])\n",
    "        ax.set_xlabel('Generation')\n",
    "        ax.set_xticks(np.arange(0, gens,5))\n",
    "        ax.yaxis.label.set_fontsize(15)\n",
    "        \n",
    "        for j in range(gens):\n",
    "            ax.scatter(j, holder[list(holder.keys())[i]][j], c='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "nbpresent": {
     "id": "e706d97d-aa64-467d-9a60-b0c59b93d73c"
    }
   },
   "source": [
    "## Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "0e7479aa-750c-468f-a0ab-858c93fae22b"
    }
   },
   "outputs": [],
   "source": [
    "progressplotter(testing2, clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "f7db2bd4-e287-4205-8bc8-94de2fcf6b57"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "progressplotter(testing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "419874da-e8ad-4e56-becf-733e3d14b2b8"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diffplotter(testing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "ab2819d2-e3f3-411e-9330-995f38a847e2"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bestplotter(testing2, k=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "4b87312c-f254-4778-83ab-9827311afbaa"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avgplotter(testing2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "80e3a110-b0de-49f7-975e-474e849494f5"
    }
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "435e476e-9db8-4380-b35a-fdd71ef8bee3"
    }
   },
   "outputs": [],
   "source": [
    "def rebuild_from_save(optimizer, generation, position):\n",
    "    \n",
    "    genome = optimizer.genome_history[generation][position]\n",
    "    \n",
    "    net = NetFromBuildInfo(genome)\n",
    "    \n",
    "    net.load_state_dict(torch.load(r\"D:\\Models\\NeuroEvolution\\{}-{}\".format(generation, position)))\n",
    "    \n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "c88f8ebd-ddcf-4f70-9799-9db3f504e9dc"
    }
   },
   "outputs": [],
   "source": [
    "def sanity_check(optimizer, test_loader):\n",
    "    \n",
    "    for generation in optimizer.test_results:\n",
    "        print('generation {}: \\n'.format(generation))\n",
    "        for i, result in enumerate(optimizer.test_results[generation]['correct']):\n",
    "            \n",
    "            mod = rebuild_from_save(optimizer, generation, i)\n",
    "            _, rebuild_result = test(mod, test_loader, adversarial=True, eps=0.5)\n",
    "            \n",
    "            if result == rebuild_result:\n",
    "                print(\"result = {}, rebuild result = {}. (equal)\".format(result, rebuild_result))\n",
    "            else:\n",
    "                print(\"result = {}, rebuild result = {}. (different!!)\".format(result, rebuild_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "277bb9ca-cb4d-4800-b64f-39e6b3cde86b"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sanity_check(testing2, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cddeaa20-1083-4546-9684-807ab7ff5e72"
    }
   },
   "source": [
    "# Best model plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "9720c32f-3745-4d12-a52f-2b5ca77610dc"
    }
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "1500d3bf-6976-45c2-b6b0-0b3d426f493e"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_model(optimizer, adversarial=True):\n",
    "    current_best = 0\n",
    "    for i, gen in enumerate(optimizer.test_results):\n",
    "        if adversarial: \n",
    "            generation_correct = optimizer.test_results[gen]['correct']\n",
    "        else:\n",
    "            generation_correct = optimizer.test_results[gen]['clean_correct']\n",
    "        for j, score in enumerate(generation_correct):\n",
    "            if score > current_best:\n",
    "                best_gen = gen\n",
    "                best_pos = j\n",
    "                current_best = score\n",
    "    clean_score = optimizer.test_results[best_gen]['clean_correct'][best_pos]\n",
    "    adv_score = optimizer.test_results[best_gen]['correct'][best_pos]\n",
    "                \n",
    "    return [best_gen, clean_score, adv_score, rebuild_from_save(optimizer, best_gen, best_pos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "496f4058-22bc-4af3-a2f4-00dca78e35d5"
    }
   },
   "outputs": [],
   "source": [
    "def best_printer(optimizer):\n",
    "    holdict = {}\n",
    "    holdict['best_clean'] = {}\n",
    "    holdict['best_adversarial'] = {}\n",
    "    \n",
    "    holdict['best_clean']['generation'] , \\\n",
    "    holdict['best_clean']['clean'], \\\n",
    "    holdict['best_clean']['adversarial'], _ = get_best_model(testing2, adversarial=False)\n",
    "    \n",
    "    holdict['best_adversarial']['generation'] , \\\n",
    "    holdict['best_adversarial']['clean'], \\\n",
    "    holdict['best_adversarial']['adversarial'], _ = get_best_model(testing2, adversarial=True)\n",
    "    \n",
    "    return pd.DataFrame(holdict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "0435b368-6a69-463f-99fe-c0ce9fdd84c1"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def multi_plot(optimizer, data_loader, adversarial=False, eps=0.5):\n",
    "    \n",
    "    best_gen, best_clean_score, best_adv_score, best_model = get_best_model(optimizer)\n",
    "    batch = next(iter(data_loader))\n",
    "    \n",
    "    print(\"Showing best model which was found in generation {}\\n\"\n",
    "          \"Clean accuracy = {}\\nadversarial accuracy ={}\\n\\n\"\n",
    "         \"Model: \\n\\n\".format(best_gen, best_clean_score,\n",
    "                           best_adv_score), best_model, \"\\n\\n\",\n",
    "          \"Images below are {}\"\n",
    "          .format('adversarial' if adversarial else 'clean'))\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "    counter=0\n",
    "    for i in range(len(batch[1])):\n",
    "        if batch[1][i].item() == counter:\n",
    "            #do stuff\n",
    "            counter+=1\n",
    "            if counter == 10: break\n",
    "            ax = fig.add_subplot(3,3, counter)\n",
    "            if adversarial:\n",
    "                image, _, _ = fgsm(best_model, batch[0][i].view(1,1,28,28).cuda(),\n",
    "                                   batch[1][i].view(1), eps=eps, batch=False)      \n",
    "            else:\n",
    "                image = batch[0][i]\n",
    "            softmax = F.softmax(best_model(image.view(1,1,28,28).cuda()), dim=1)\n",
    "            prediction = softmax.argmax()\n",
    "            prediction_pct = softmax.max()\n",
    "            ax.imshow(image.detach().cpu().numpy().reshape(28,28))\n",
    "            ax.text(x=3, y=31, s=\"Predicted: {x} ({y:.2f})\"\n",
    "                     .format(x=prediction, y=prediction_pct), fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "8fb2bc4c-96db-4ee8-8b4c-3e5ed3a5e02b"
    }
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "e32e303c-4683-4049-9a28-996b70ed3f5f"
    }
   },
   "outputs": [],
   "source": [
    "best_printer(testing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "82a144f5-2199-4826-bc6d-a3bc8d5b2bce"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multi_plot(testing2, test_loader, adversarial=True, eps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "45b5cd68-7186-4aec-b0f1-6f6c67cdc5ef"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multi_plot(testing2, test_loader, adversarial=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ffed394f-e254-4c4d-af58-4478744a2c51"
    }
   },
   "source": [
    "# Comparison plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "79bd33c1-356a-4788-bd62-38d1f512345f"
    }
   },
   "source": [
    "## Definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "3ff3ccaf-9ec1-4b25-a022-4da62742edd3"
    }
   },
   "outputs": [],
   "source": [
    "_,_,_, best_model = get_best_model(testing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "2f889edb-58d3-4f13-83c9-1e1b82955fe1"
    }
   },
   "outputs": [],
   "source": [
    "eps_dict = {}\n",
    "\n",
    "for i in tqdm_notebook(range(101)):\n",
    "    eps_dict[i/100] = test(best_model, test_loader, adversarial = True, eps=i/100)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "38b9a283-b92b-424e-bd0a-5d6f31236eeb"
    }
   },
   "outputs": [],
   "source": [
    "df =pd.DataFrame(eps_dict, index=['Accuracy']).T\n",
    "df.index.name = 'epsilon'\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "e3a8704d-e42b-4d31-b433-288cfba5c2c9"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.plot('epsilon', figsize=(10,5), ylim=[0,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "769ea7f1-2f47-4f63-a245-0051986e4d17"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbpresent": {
     "id": "45ab1f8e-cb90-47fa-93b2-0e8002b7a744"
    }
   },
   "source": [
    "## bokeh progress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "e3ea7c15-9480-4cbb-b043-1c46a1680542"
    }
   },
   "outputs": [],
   "source": [
    "def dataframer(optimizer):\n",
    "    \n",
    "    number_of_layers = []\n",
    "    learning_rate = []\n",
    "    act_func = []\n",
    "    number_of_units_1 = []\n",
    "    dropout_rate = []\n",
    "    genome_hist = []\n",
    "    generations = []\n",
    "    clean_scores = []\n",
    "    adv_scores = []\n",
    "    \n",
    "    for generation in optimizer.test_results:\n",
    "\n",
    "        scores = optimizer.test_results[generation]\n",
    "        genomes = optimizer.genome_history[generation]\n",
    "\n",
    "        clean_scores += scores['clean_correct']\n",
    "        adv_scores += scores['correct']\n",
    "\n",
    "        for genome in genomes:\n",
    "            \n",
    "            generations.append(generation)\n",
    "            genome_hist.append(genome)\n",
    "            number_of_layers.append(genome['nb_layers'])\n",
    "            learning_rate.append(genome['lr'])\n",
    "\n",
    "            act_func.append(genome['layers'][0]['activation'])\n",
    "            number_of_units_1.append(genome['layers'][0]['nb_units'])\n",
    "            dropout_rate.append(genome['layers'][0]['dropout_rate'])\n",
    "\n",
    "            df = pd.DataFrame([generations, clean_scores, adv_scores, number_of_layers,\n",
    "                             learning_rate, act_func, \n",
    "                             number_of_units_1, dropout_rate, genome_hist]).T\n",
    "\n",
    "            df.columns = ['Generation', 'Clean','Adversarial','No_layers',\n",
    "                          'Lr', 'Act_func', 'Nb_units', 'Dropout', 'Genome']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "952a3929-571e-4566-8a63-979a50eebc1c"
    }
   },
   "outputs": [],
   "source": [
    "df = dataframer(testing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "dc9fba66-2b73-4769-822a-65dcd8a5e125"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle(r\"../data/neuroevolution2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "72eaaf89-1905-4d4e-a504-84b5db58388d"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r\"../data/neuroevolution1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "3b00d5ab-cc88-4f38-b562-0076e416056d"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "76fcd70a-7f13-4c5f-9695-aabaaeb53821"
    }
   },
   "outputs": [],
   "source": [
    "def f(x, y, x2, y2, gen):\n",
    "    if gen == 'all':\n",
    "        source = ColumnDataSource(df.iloc[:, :-1])#last column contains dicts which causes bokeh to fail\n",
    "    else: \n",
    "        source = ColumnDataSource(df[df['Generation']==gen].iloc[:, :-1]) \n",
    "    \n",
    "    tiplist = [(\"Accuracy\", \"@Clean\"), \n",
    "            (\"Adversarial accuracy\", \"@Adversarial\"),\n",
    "            (\"Number of layers\", \"@No_layers\"),\n",
    "            (\"Generation\", \"@Generation\"),\n",
    "            (\"Activation function\", \"@Act_func\"),\n",
    "              (\"Dropout\", \"@Dropout\")]\n",
    "    \n",
    "    options = dict(plot_width=400, plot_height=400,\n",
    "                   tools=\"pan,wheel_zoom,box_zoom,box_select,lasso_select\",\n",
    "                  active_scroll= 'wheel_zoom')\n",
    "\n",
    "    p1 = figure(title=\"{} vs {}\".format(y, x), **options)\n",
    "    p1.scatter(x, y, color=\"blue\", source=source,\n",
    "               hover_line_color=\"black\", radius=0.1)\n",
    "    p1.xaxis.axis_label = x\n",
    "    p1.yaxis.axis_label = y\n",
    "    if y in ['Adversarial', 'Clean']:\n",
    "        p1.y_range.start = -1000\n",
    "        p1.y_range.end = 11000\n",
    "    p1.add_tools(HoverTool(tooltips=tiplist))\n",
    "\n",
    "    p2 = figure(title=\"{} vs {}\".format(y2, x2), **options)\n",
    "    p2.scatter(x2, y2, color=\"green\", source=source, \n",
    "               hover_line_color=\"black\", radius=0.1)\n",
    "    p2.xaxis.axis_label = x2\n",
    "    p2.yaxis.axis_label = y2\n",
    "    if y2 in ['Adversarial', 'Clean']:\n",
    "        p2.y_range.start = -1000\n",
    "        p2.y_range.end = 11000\n",
    "    p2.add_tools(HoverTool(tooltips=tiplist))\n",
    "\n",
    "    p = gridplot([[ p1, p2]], toolbar_location=\"left\")\n",
    "\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "c077670b-8632-4efe-b63d-7708e99490a5"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opts = df.columns.tolist()[:-1] #last column contains dicts which causes bokeh to fail\n",
    "gen_opts = ['all'] + df['Generation'].unique().tolist() \n",
    "y1_opts = opts[2:] + opts[:2]\n",
    "y2_opts = opts[1:] + opts[:1]\n",
    "interactive_plot = interactive(f, x=opts, y=y1_opts, x2=opts, y2=y2_opts, gen=gen_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbpresent": {
     "id": "9398a324-cfa1-4a6b-a48c-7002b4336ab8"
    }
   },
   "outputs": [],
   "source": [
    "interactive_plot"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
