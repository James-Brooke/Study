{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from operator import itemgetter\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Clean MNIST loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,)) #normalise pixels using mean and stdev\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #normalise to range -1 to 1\n",
    "                   ])\n",
    "\n",
    "\n",
    "\n",
    "MNIST_train = datasets.MNIST(r'D:\\Data_sets/MNIST', train=True, download=True,\n",
    "                   transform=transform)\n",
    "\n",
    "MNIST_test = datasets.MNIST(r'D:\\Data_sets/MNIST', train=False, download=True,\n",
    "                   transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(MNIST_train, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(MNIST_test,\n",
    "                                          batch_size=1000, \n",
    "                                          shuffle=True, \n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Adversarial loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class AdversarialDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"FGSM adversarials of MNIST test set\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "\n",
    "        self.adversarials = np.load(root_dir+'/adversarials.npy')\n",
    "        self.labels = np.load(root_dir+'/labels.npy')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.adversarials[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adversarials = AdversarialDataset('D:/Data_sets/Adversarial/MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adversarial_loader = torch.utils.data.DataLoader(adversarials, \n",
    "                                           batch_size=1000, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LAYER_SPACE = {\n",
    "    'nb_units':{'lb': 128, 'ub':1024, 'mutate': 0.15},\n",
    "    'dropout_rate': {'lb': 0.0, 'ub': 0.7, 'mutate': 0.2},\n",
    "    'activation': {'func': ['linear','tanh','relu','sigmoid','elu'], 'mutate':0.2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NET_SPACE = {\n",
    "    'nb_layers': {'lb': 1, 'ub': 3, 'mutate': 0.15},\n",
    "    'lr': {'lb': 0.001, 'ub':0.1, 'mutate': 0.15},\n",
    "    'weight_decay': {'lb': 0.00001, 'ub': 0.0004, 'mutate':0.2},\n",
    "    'optimizer': {'func': ['sgd', 'adam', 'adadelta','rmsprop'], 'mutate': 0.2}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Randomise network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def random_value(space):\n",
    "    \"\"\"Returns random value from space.\"\"\"\n",
    "    \n",
    "    val = None\n",
    "    \n",
    "    if 'func' in space: #randomise optimiser or activation function\n",
    "        val = random.sample(space['func'], 1)[0] \n",
    "    \n",
    "    elif isinstance(space['lb'], int): #randomise number of units or layers\n",
    "        val = random.randint(space['lb'], space['ub'])\n",
    "    \n",
    "    else: #randomise percentages, i.e. dropout rates or weight decay\n",
    "        val = random.random() * (space['ub'] - space['lb']) + space['lb']\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def randomize_network(layer_space, net_space): \n",
    "    \"\"\"Returns a randomised neural network\"\"\"\n",
    "    net = {}\n",
    "    \n",
    "    for key in net_space.keys():\n",
    "        net[key] = random_value(net_space[key])\n",
    "        \n",
    "    layers = []\n",
    "    \n",
    "    for i in range(net['nb_layers']):\n",
    "        layer = {}\n",
    "        for key in layer_space.keys():\n",
    "            layer[key] = random_value(layer_space[key])\n",
    "        layers.append(layer)\n",
    "        net['layers'] = layers\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [{'activation': 'linear',\n",
       "   'dropout_rate': 0.05875328570846247,\n",
       "   'nb_units': 244},\n",
       "  {'activation': 'linear',\n",
       "   'dropout_rate': 0.10278691060470113,\n",
       "   'nb_units': 443},\n",
       "  {'activation': 'sigmoid',\n",
       "   'dropout_rate': 0.5430231617074555,\n",
       "   'nb_units': 312}],\n",
       " 'lr': 0.08548772787644217,\n",
       " 'nb_layers': 3,\n",
       " 'optimizer': 'adadelta',\n",
       " 'weight_decay': 0.00020324598051495654}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomize_network(LAYER_SPACE, NET_SPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mutate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mutate_net(nnet, layer_space, net_space):\n",
    "    \n",
    "    net = copy.deepcopy(nnet)\n",
    "    \n",
    "    \n",
    "    # mutate optimizer\n",
    "    for k in ['lr', 'weight_decay', 'optimizer']:\n",
    "        if random.random() < net_space[k]['mutate']:\n",
    "            net[k] = random_value(net_space[k])\n",
    "    \n",
    "    \n",
    "    # mutate layers\n",
    "    for layer in net['layers']:\n",
    "        for k in layer_space.keys():\n",
    "            if random.random() < layer_space[k]['mutate']:\n",
    "                layer[k] = random_value(layer_space[k])\n",
    "                \n",
    "                \n",
    "    # mutate number of layers -- 50% add 50% remove\n",
    "    if random.random() < net_space['nb_layers']['mutate']:\n",
    "        if net['nb_layers'] <= net_space['nb_layers']['ub']:\n",
    "            if random.random()< 0.5 and \\\n",
    "            net['nb_layers'] < net_space['nb_layers']['ub']:\n",
    "                layer = {}\n",
    "                for key in layer_space.keys():\n",
    "                    layer[key] = random_value(layer_space[key])\n",
    "                net['layers'].append(layer)      \n",
    "            else:\n",
    "                if net['nb_layers'] > 1:\n",
    "                    net['layers'].pop()\n",
    "\n",
    "                \n",
    "            # value & id update\n",
    "            net['nb_layers'] = len(net['layers'])         \n",
    "            \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \"\"\"Flattens input to vector size (batchsize, 1)\n",
    "    (for use in NetFromBuildInfo).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NetFromBuildInfo(nn.Module):\n",
    "    def __init__(self, build_info):\n",
    "        super(NetFromBuildInfo, self).__init__()\n",
    "        \n",
    "        self.activation_dict = {\n",
    "            'tanh': nn.Tanh(),\n",
    "            'relu': nn.ReLU(),\n",
    "            'sigmoid': nn.Sigmoid(),\n",
    "            'elu': nn.ELU()\n",
    "            }\n",
    "\n",
    "        #NETWORK DEFINITION\n",
    "        \n",
    "        previous_units = 28 * 28 #MNIST shape\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add_module('flatten', Flatten())\n",
    "         \n",
    "        for i, layer_info in enumerate(build_info['layers']):\n",
    "            i = str(i)\n",
    "            \n",
    "            self.model.add_module(\n",
    "                'fc_' + i,\n",
    "                nn.Linear(previous_units, layer_info['nb_units'])\n",
    "                )\n",
    "            \n",
    "            previous_units = layer_info['nb_units']\n",
    "            \n",
    "            self.model.add_module(\n",
    "                'dropout_' + i,\n",
    "                nn.Dropout(p=layer_info['dropout_rate'])\n",
    "                )\n",
    "            if layer_info['activation'] == 'linear':\n",
    "                continue #linear activation is identity function\n",
    "            self.model.add_module(\n",
    "                layer_info['activation']+ i,\n",
    "                self.activation_dict[layer_info['activation']])\n",
    "\n",
    "        self.model.add_module(\n",
    "            'logits',\n",
    "            nn.Linear(previous_units, 10) #10 MNIST classes\n",
    "            )\n",
    "        \n",
    "        \n",
    "        ##OPTIMIZER\n",
    "\n",
    "        self.opt_args = {#'params': self.model.parameters(),\n",
    "                 'weight_decay': build_info['weight_decay'],\n",
    "                 'lr': build_info['lr']\n",
    "                 }\n",
    "        \n",
    "        self.optimizer_dict = {\n",
    "            'adam': optim.Adam(self.model.parameters(),**self.opt_args),\n",
    "            'rmsprop': optim.RMSprop(self.model.parameters(),**self.opt_args),\n",
    "            'adadelta':optim.Adadelta(self.model.parameters(),**self.opt_args),\n",
    "            'sgd': optim.SGD(self.model.parameters(), **self.opt_args, momentum=0.9) #momentum to train faster\n",
    "            }\n",
    "\n",
    "        self.optimizer = self.optimizer_dict[build_info['optimizer']]\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train test helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss /= len(train_loader.dataset)    \n",
    "    \n",
    "    if epoch % 3 == 0:\n",
    "        print('Train Epoch: {} \\t Loss: {:.6f}'.format(epoch, running_loss ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    \n",
    "    model.train(False)\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    \n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evolution optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TournamentOptimizer:\n",
    "    \"\"\"Define a tournament play selection process.\"\"\"\n",
    "\n",
    "    def __init__(self, population_sz, layer_space, net_space, init_fn, mutate_fn, builder_fn,\n",
    "                 train_fn, test_fn, data_loader, test_loader, adversarial_loader):\n",
    "        \n",
    "        self.init_fn = init_fn\n",
    "        self.layer_space = layer_space\n",
    "        self.net_space = net_space\n",
    "        self.mutate_fn = mutate_fn\n",
    "        self.builder_fn = builder_fn\n",
    "        self.train = train_fn\n",
    "        self.test = test_fn\n",
    "        self.dataloader = data_loader\n",
    "        self.testloader = test_loader\n",
    "        self.population_sz = population_sz\n",
    "        self.adversarials = adversarial_loader\n",
    "        \n",
    "        torch.manual_seed(1);\n",
    "        \n",
    "        self.genomes = [init_fn(self.layer_space, self.net_space) for i in range(population_sz)]   \n",
    "        self.population = [NetFromBuildInfo(i).cuda() for i in self.genomes] #randomize population of nets     \n",
    "        \n",
    "        self.test_results = {} \n",
    "        self.genome_history = {} \n",
    "\n",
    "        self.generation = 0\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Tournament evolution step.\"\"\"\n",
    "\n",
    "        genome_holder = [] \n",
    "        \n",
    "        self.generation += 1\n",
    "        \n",
    "        self.genome_history[self.generation] = self.genomes\n",
    "\n",
    "        self.train_nets()\n",
    "        self.evaluate_nets()\n",
    "\n",
    "        mean = np.mean(self.test_results[self.generation]['correct'])\n",
    "        best = np.max(self.test_results[self.generation]['correct'])\n",
    "        \n",
    "        print('\\nPopulation mean:{} max:{}'.format(mean, best))\n",
    "        \n",
    "        \n",
    "        children = []\n",
    "        n_elite = 2\n",
    "        sorted_pop = np.argsort(self.test_results[self.generation]['correct'])[::-1]\n",
    "        elite = sorted_pop[:n_elite]\n",
    "        \n",
    "\n",
    "\n",
    "        # elites always included in the next population\n",
    "        self.elite = []\n",
    "        print('\\nTop performers:')\n",
    "        for no, i in enumerate(elite):\n",
    "            self.elite.append((self.test_results[self.generation]['correct'][i], \n",
    "                               self.population[i]))    \n",
    "            \n",
    "            genome_holder.append(self.genomes[i])\n",
    "            \n",
    "            print(\"{}: score:{}\".format(no, self.test_results[self.generation]['correct'][i]))   \n",
    "            \n",
    "            children.append(self.population[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "        #https://stackoverflow.com/questions/31933784/tournament-selection-in-genetic-algorithm\n",
    "        p = 0.85 # winner probability \n",
    "        tournament_size = 3\n",
    "        probs = [p*((1-p)**i) for i in range(tournament_size-1)]\n",
    "        probs.append(1-np.sum(probs))\n",
    "        #probs = [0.85, 0.1275, 0.0224]\n",
    "        \n",
    "        while len(children) < self.population_sz:\n",
    "            pop = range(len(self.population))\n",
    "            sel_k = random.sample(pop, k=tournament_size)\n",
    "            fitness_k = list(np.array(self.test_results[self.generation]['correct'])[sel_k])\n",
    "            selected = zip(sel_k, fitness_k)\n",
    "            rank = sorted(selected, key=itemgetter(1), reverse=True)\n",
    "            pick = np.random.choice(tournament_size, size=1, p=probs)[0]\n",
    "            best = rank[pick][0]\n",
    "            genome = self.mutate_fn(self.genomes[best], self.layer_space, self.net_space)\n",
    "            print('mutated: ', best)\n",
    "            \n",
    "            genome_holder.append(genome)\n",
    "            model =  self.builder_fn(genome).cuda()\n",
    "            children.append(model)\n",
    "\n",
    "\n",
    "            \n",
    "        self.population = children\n",
    "        self.genomes = genome_holder\n",
    "\n",
    "        \n",
    "        #<----------- add all new genomes to genome history --------->\n",
    "        \n",
    "    def train_nets(self):\n",
    "        \n",
    "        for i, net in enumerate(self.population):\n",
    "            for epoch in range(1, 2):\n",
    "                \n",
    "                torch.manual_seed(1);\n",
    "                \n",
    "                self.train(net, self.dataloader, net.optimizer, epoch)\n",
    "                print('model {} trained'.format(i))\n",
    "                \n",
    "                fp = r\"D:\\Models\\NeuroEvolution/{}-{}\".format(self.generation, i)\n",
    "                torch.save(net.state_dict(), fp)\n",
    "                \n",
    "                \n",
    "                \n",
    "    def evaluate_nets(self):\n",
    "        \"\"\"evaluate the models.\"\"\"\n",
    "        \n",
    "        losses = []\n",
    "        corrects = []\n",
    "        \n",
    "        self.test_results[self.generation] = {}\n",
    "        \n",
    "        for i in range(len(self.population)):\n",
    "            net = self.population[i]\n",
    "            loss, correct = self.test(net, self.adversarials) #CHANGE HERE FOR CLEAN/ADVERSARIAL optimizing\n",
    "            \n",
    "            losses.append(loss)\n",
    "            corrects.append(correct)\n",
    "        \n",
    "        self.test_results[self.generation]['losses'] = losses\n",
    "        self.test_results[self.generation]['correct'] = corrects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = TournamentOptimizer(30, LAYER_SPACE, NET_SPACE, randomize_network, \n",
    "                           mutate_net, NetFromBuildInfo, train, test,\n",
    "                          train_loader, test_loader, adversarial_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 10 trained\n",
      "model 11 trained\n",
      "model 12 trained\n",
      "model 13 trained\n",
      "model 14 trained\n",
      "model 15 trained\n",
      "model 16 trained\n",
      "model 17 trained\n",
      "model 18 trained\n",
      "model 19 trained\n",
      "model 20 trained\n",
      "model 21 trained\n",
      "model 22 trained\n",
      "model 23 trained\n",
      "model 24 trained\n",
      "model 25 trained\n",
      "model 26 trained\n",
      "model 27 trained\n",
      "model 28 trained\n",
      "model 29 trained\n",
      "\n",
      "Population mean:1840.9333333333334 max:2760\n",
      "\n",
      "Top performers:\n",
      "0: score:2760\n",
      "1: score:2505\n",
      "mutated:  3\n",
      "mutated:  27\n",
      "mutated:  4\n",
      "mutated:  3\n",
      "mutated:  4\n",
      "mutated:  29\n",
      "mutated:  21\n",
      "mutated:  19\n",
      "mutated:  18\n",
      "mutated:  29\n",
      "mutated:  7\n",
      "mutated:  11\n",
      "mutated:  25\n",
      "mutated:  15\n",
      "mutated:  10\n",
      "mutated:  15\n",
      "mutated:  16\n",
      "mutated:  29\n",
      "mutated:  17\n",
      "mutated:  3\n",
      "mutated:  23\n",
      "mutated:  0\n",
      "mutated:  21\n",
      "mutated:  29\n",
      "mutated:  19\n",
      "mutated:  12\n",
      "mutated:  20\n",
      "mutated:  29\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    testing.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'correct': [2005,\n",
       "   983,\n",
       "   1800,\n",
       "   1258,\n",
       "   2256,\n",
       "   1265,\n",
       "   1851,\n",
       "   1802,\n",
       "   1232,\n",
       "   1689,\n",
       "   1728,\n",
       "   1028,\n",
       "   502,\n",
       "   1391,\n",
       "   1417,\n",
       "   967,\n",
       "   1954,\n",
       "   1863,\n",
       "   1289,\n",
       "   980,\n",
       "   1336,\n",
       "   1744,\n",
       "   2329,\n",
       "   1471,\n",
       "   958,\n",
       "   1223,\n",
       "   1355,\n",
       "   1153,\n",
       "   1077,\n",
       "   2039],\n",
       "  'losses': [2.278823974609375,\n",
       "   5028.9832,\n",
       "   2.0798281982421876,\n",
       "   4.3766138671875,\n",
       "   2.068897998046875,\n",
       "   3.26730341796875,\n",
       "   2.2750092041015626,\n",
       "   2.5014030517578125,\n",
       "   230.252775,\n",
       "   2.2676238037109373,\n",
       "   2.285697412109375,\n",
       "   8870224.896,\n",
       "   5.26239052734375,\n",
       "   2.6239562255859377,\n",
       "   2.164543896484375,\n",
       "   3.5549892333984374,\n",
       "   147.4544546875,\n",
       "   338.548384375,\n",
       "   2.300280078125,\n",
       "   nan,\n",
       "   2.726551611328125,\n",
       "   4.89104619140625,\n",
       "   7.02229619140625,\n",
       "   2.6457461669921876,\n",
       "   4.1087470703125,\n",
       "   2.436090966796875,\n",
       "   2.4254484619140624,\n",
       "   2.4861462646484376,\n",
       "   6000.79775,\n",
       "   2.2147043701171873]},\n",
       " 2: {'correct': [2009,\n",
       "   2034,\n",
       "   1940,\n",
       "   1697,\n",
       "   1065,\n",
       "   1385,\n",
       "   1915,\n",
       "   1496,\n",
       "   1645,\n",
       "   961,\n",
       "   1951,\n",
       "   1346,\n",
       "   1455,\n",
       "   1676,\n",
       "   958,\n",
       "   2083,\n",
       "   2087,\n",
       "   945,\n",
       "   2226,\n",
       "   1371,\n",
       "   1027,\n",
       "   1321,\n",
       "   1280,\n",
       "   1820,\n",
       "   1938,\n",
       "   1305,\n",
       "   1722,\n",
       "   1001,\n",
       "   1897,\n",
       "   1326],\n",
       "  'losses': [3.54627080078125,\n",
       "   2.057972961425781,\n",
       "   5.97762841796875,\n",
       "   2.40098681640625,\n",
       "   5.39517021484375,\n",
       "   2.2961361328125,\n",
       "   2.221277783203125,\n",
       "   2.3765858642578124,\n",
       "   11.5548416015625,\n",
       "   3.094794677734375,\n",
       "   2.074284729003906,\n",
       "   2.409730810546875,\n",
       "   2.156866015625,\n",
       "   8.204082373046875,\n",
       "   5.4439248046875,\n",
       "   2.210108935546875,\n",
       "   8.172333740234375,\n",
       "   3.2324564453125,\n",
       "   7.478514697265625,\n",
       "   2.5912439697265626,\n",
       "   11170.8927,\n",
       "   2.1606494384765624,\n",
       "   100.683521875,\n",
       "   146.3162671875,\n",
       "   2.2223140625,\n",
       "   2.2254204833984375,\n",
       "   2.50296923828125,\n",
       "   4.779305078125,\n",
       "   4.876099560546875,\n",
       "   2.4245877197265626]},\n",
       " 3: {'correct': [1919,\n",
       "   2319,\n",
       "   958,\n",
       "   1894,\n",
       "   1358,\n",
       "   1210,\n",
       "   1627,\n",
       "   1057,\n",
       "   2104,\n",
       "   1640,\n",
       "   980,\n",
       "   2053,\n",
       "   958,\n",
       "   1776,\n",
       "   1529,\n",
       "   1909,\n",
       "   1822,\n",
       "   1926,\n",
       "   1494,\n",
       "   1730,\n",
       "   2590,\n",
       "   946,\n",
       "   2292,\n",
       "   2542,\n",
       "   1715,\n",
       "   1686,\n",
       "   1453,\n",
       "   1831,\n",
       "   980,\n",
       "   1806],\n",
       "  'losses': [3.222986083984375,\n",
       "   4.0539802734375,\n",
       "   2.548697265625,\n",
       "   4.129394262695312,\n",
       "   2.669371337890625,\n",
       "   2.46682490234375,\n",
       "   6.96600595703125,\n",
       "   7554.42175,\n",
       "   2.21163681640625,\n",
       "   2.104807275390625,\n",
       "   nan,\n",
       "   2.199433837890625,\n",
       "   6.105171728515625,\n",
       "   2.5551626953125,\n",
       "   2.31297900390625,\n",
       "   2.07849345703125,\n",
       "   2.1357996337890626,\n",
       "   4.809207080078125,\n",
       "   173.740340625,\n",
       "   2.4093680908203123,\n",
       "   7.012537744140625,\n",
       "   3.8784407470703126,\n",
       "   2.0836832275390624,\n",
       "   8.12520849609375,\n",
       "   4.076741870117187,\n",
       "   2.358187255859375,\n",
       "   2.4077615234375,\n",
       "   7.355587841796875,\n",
       "   nan,\n",
       "   2.7902637939453125]},\n",
       " 4: {'correct': [1823,\n",
       "   1992,\n",
       "   2011,\n",
       "   1032,\n",
       "   1806,\n",
       "   1874,\n",
       "   1907,\n",
       "   2004,\n",
       "   1858,\n",
       "   2322,\n",
       "   1597,\n",
       "   1871,\n",
       "   2454,\n",
       "   1859,\n",
       "   929,\n",
       "   1630,\n",
       "   1793,\n",
       "   2005,\n",
       "   979,\n",
       "   1924,\n",
       "   1098,\n",
       "   2011,\n",
       "   958,\n",
       "   2572,\n",
       "   2381,\n",
       "   1213,\n",
       "   1541,\n",
       "   2425,\n",
       "   2305,\n",
       "   2527],\n",
       "  'losses': [2.6338515869140626,\n",
       "   4.505665576171875,\n",
       "   4.6969310546875,\n",
       "   2.2941115234375,\n",
       "   2.1901260009765626,\n",
       "   6.53142685546875,\n",
       "   2.422041357421875,\n",
       "   7.146131494140625,\n",
       "   2.427860595703125,\n",
       "   6.603024462890625,\n",
       "   3.5321579345703125,\n",
       "   2.0891597412109375,\n",
       "   2.068804968261719,\n",
       "   2.394473681640625,\n",
       "   8.374692919921875,\n",
       "   2.1594099609375,\n",
       "   2.396337890625,\n",
       "   10.449412890625,\n",
       "   7.99726044921875,\n",
       "   2.0796739990234374,\n",
       "   7.332064892578125,\n",
       "   2.115060107421875,\n",
       "   5.978383935546875,\n",
       "   2.1917452880859374,\n",
       "   8.134157177734375,\n",
       "   2.945855908203125,\n",
       "   2.242148779296875,\n",
       "   8.87206474609375,\n",
       "   2.086467919921875,\n",
       "   7.026108837890625]}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def progressplotter(optimizer):\n",
    "    \n",
    "    means = []\n",
    "    \n",
    "    fig = plt.subplot()\n",
    "    \n",
    "    gens = range(len(optimizer.test_results))\n",
    "    popsize = len(optimizer.test_results[1]['correct'])\n",
    "    \n",
    "    for i in gens:\n",
    "        fig.scatter([i for j in range(popsize)], optimizer.test_results[i+1]['correct'])\n",
    "        mean = np.mean(optimizer.test_results[i+1]['correct'])\n",
    "        means.append(mean)\n",
    "        fig.scatter(i, mean, c=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.scatter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD3CAYAAAAT+Z8iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d205339f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progressplotter(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d203cf8978>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD3CAYAAADmBxSSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwKBsSSpkj3oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d203cf8c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.subplot()\n",
    "fig.scatter(range(3), [1, 2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(testing.test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rebuild_from_save(optimizer, generation, position):\n",
    "    \n",
    "    genome = optimizer.genome_history[generation][position]\n",
    "    \n",
    "    net = NetFromBuildInfo(genome)\n",
    "    \n",
    "    net.load_state_dict(torch.load(r\"D:\\Models\\NeuroEvolution\\{}-{}\".format(generation, position)))\n",
    "    \n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanity_check(optimizer, test_loader):\n",
    "    \n",
    "    for generation in optimizer.test_results:\n",
    "        print('generation {}: \\n'.format(generation))\n",
    "        for i, result in enumerate(optimizer.test_results[generation]['correct']):\n",
    "            \n",
    "            mod = rebuild_from_save(optimizer, generation, i)\n",
    "            _, rebuild_result = test(mod, test_loader)\n",
    "            \n",
    "            if result == rebuild_result:\n",
    "                print(\"result = {}, rebuild result = {}. (equal)\".format(result, rebuild_result))\n",
    "            else:\n",
    "                print(\"result = {}, rebuild result = {}. (different!!)\".format(result, rebuild_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation 1: \n",
      "\n",
      "result = 1215, rebuild result = 1215. (equal)\n",
      "result = 1822, rebuild result = 1822. (equal)\n",
      "result = 1407, rebuild result = 1407. (equal)\n"
     ]
    }
   ],
   "source": [
    "sanity_check(testing, adversarial_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
