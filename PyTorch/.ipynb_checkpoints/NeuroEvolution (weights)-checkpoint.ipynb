{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor()])\n",
    "\n",
    "MNIST_train = datasets.MNIST(r'D:\\Data_sets/MNIST', \n",
    "                            train=True, download=True,\n",
    "                            transform=transform)\n",
    "\n",
    "MNIST_test = datasets.MNIST(r'D:\\Data_sets/MNIST', \n",
    "                            train=False, download=True,\n",
    "                            transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                            MNIST_train, batch_size=64, \n",
    "                            shuffle=True, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(MNIST_test,\n",
    "                            batch_size=1000, shuffle=True, \n",
    "                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(test_loader))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        #self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNet(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(x, chance, mean, std):\n",
    "    if np.random.rand() > (1-chance): \n",
    "        x = np.random.normal(loc=mean, scale=std)\n",
    "        return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_weights(params, chance):\n",
    "    mean = params.detach().mean()\n",
    "    std = params.detach().std()\n",
    "    return params.detach().apply_(lambda x: mutate(x, chance, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(model, chance):\n",
    "    params = list(model.parameters())\n",
    "    for param in params:\n",
    "        if len(param.shape) == 1:\n",
    "            param.data = mutate_weights(param, chance)\n",
    "        elif len(param.shape) == 2:\n",
    "            for inner_param in param:\n",
    "                    inner_param.data = mutate_weights(inner_param, chance)\n",
    "        else:\n",
    "            for inner_param in param:\n",
    "                for last_channel in inner_param:\n",
    "                    last_channel.data = mutate_weights(last_channel, chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(model1, model2):\n",
    "    model1_params = list(model1.parameters())\n",
    "    model2_params = list(model2.parameters())\n",
    "    \n",
    "    for i, param in enumerate(model1_params):\n",
    "        if len(param.shape) == 1:\n",
    "            split = int(np.random.uniform(low=0, high=param.shape[0]))\n",
    "            first_half = param.view(-1)[:split].data \n",
    "            second_half = model2_params[i].view(-1)[split:].data\n",
    "            comb = torch.cat((first_half, second_half)).view_as(param)\n",
    "            first_half = param.view(-1)[split:].data\n",
    "            second_half = model2_params[i].view(-1)[:split].data\n",
    "            comb2 = torch.cat((first_half, second_half)).view_as(param)\n",
    "            param.data = comb\n",
    "            model2_params[i].data = comb2\n",
    "        \n",
    "        elif len(param.shape) == 2:\n",
    "             for j, inner_param in enumerate(param):\n",
    "                split = int(np.random.uniform(low=0, high=inner_param.shape[0]))\n",
    "                first_half = inner_param.view(-1)[:split].data \n",
    "                second_half = model2_params[i][j].view(-1)[split:].data\n",
    "                comb = torch.cat((first_half, second_half)).view_as(inner_param)\n",
    "                first_half = inner_param.view(-1)[split:].data\n",
    "                second_half = model2_params[i][j].view(-1)[:split].data\n",
    "                comb2 = torch.cat((first_half, second_half)).view_as(inner_param)\n",
    "                inner_param.data = comb\n",
    "                model2_params[i][j].data = comb2\n",
    "\n",
    "        else:\n",
    "            for j, inner_param in enumerate(param):\n",
    "                for k, last_channel in enumerate(inner_param):\n",
    "                    split = int(np.random.uniform(low=0, \n",
    "                                high=last_channel.shape[0] * last_channel.shape[1]))\n",
    "                    first_half = last_channel.view(-1)[:split].data \n",
    "                    second_half = model2_params[i][j][k].view(-1)[split:].data\n",
    "                    comb = torch.cat((first_half, second_half)).view_as(last_channel)\n",
    "                    first_half = last_channel.view(-1)[split:].data\n",
    "                    second_half = model2_params[i][j][k].view(-1)[:split].data\n",
    "                    comb2 = torch.cat((first_half, second_half)).view_as(last_channel)\n",
    "                    last_channel.data = comb\n",
    "                    model2_params[i][j][k].data = comb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
