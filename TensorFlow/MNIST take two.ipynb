{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST take two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An attempt to improve the previous models accuracy by using:\n",
    "\n",
    "- The Adam optimiser https://arxiv.org/abs/1412.6980  \n",
    "- Early stopping (reuglarisation)  \n",
    "- He initialisation https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf  \n",
    "- Extra hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images[mnist.train.labels < 5]\n",
    "y_train1 = mnist.train.labels[mnist.train.labels < 5]\n",
    "X_valid1 = mnist.validation.images[mnist.validation.labels < 5]\n",
    "y_valid1 = mnist.validation.labels[mnist.validation.labels < 5]\n",
    "X_test1 = mnist.test.images[mnist.test.labels < 5]\n",
    "y_test1 = mnist.test.labels[mnist.test.labels < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer() #he initialisation for layers\n",
    "\n",
    "with tf.name_scope(\"neural_net\"): #Architecture\n",
    "    hidden1 = tf.layers.dense(X, hidden1_n, activation=tf.nn.elu, kernel_initializer=he_init, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, hidden2_n, name=\"hidden2\", kernel_initializer=he_init, activation=tf.nn.elu)\n",
    "    hidden3 = tf.layers.dense(hidden2, hidden3_n, name=\"hidden3\", kernel_initializer=he_init, activation=tf.nn.elu)\n",
    "    hidden4 = tf.layers.dense(hidden3, hidden4_n, name=\"hidden4\", kernel_initializer=he_init, activation=tf.nn.elu)\n",
    "    hidden5 = tf.layers.dense(hidden4, hidden5_n, name=\"hidden5\", kernel_initializer=he_init, activation=tf.nn.elu)\n",
    "    logits = tf.layers.dense(hidden5, outputs_n, name=\"outputs\", kernel_initializer=he_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"): # Cost function\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(cross_entropy, name = \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"): #Optimiser\n",
    "    optimiser = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    training_op = optimiser.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"): # Evaluation metric (accuracy)\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "batch_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.049299\tBest loss: 0.049299\tAccuracy: 98.59%\n",
      "1\tValidation loss: 0.044320\tBest loss: 0.044320\tAccuracy: 98.55%\n",
      "2\tValidation loss: 0.047358\tBest loss: 0.044320\tAccuracy: 98.59%\n",
      "3\tValidation loss: 0.034234\tBest loss: 0.034234\tAccuracy: 99.26%\n",
      "4\tValidation loss: 0.034486\tBest loss: 0.034234\tAccuracy: 98.98%\n",
      "5\tValidation loss: 0.045551\tBest loss: 0.034234\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.050927\tBest loss: 0.034234\tAccuracy: 98.59%\n",
      "7\tValidation loss: 0.055186\tBest loss: 0.034234\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.042415\tBest loss: 0.034234\tAccuracy: 98.98%\n",
      "9\tValidation loss: 0.051686\tBest loss: 0.034234\tAccuracy: 98.48%\n",
      "10\tValidation loss: 0.035941\tBest loss: 0.034234\tAccuracy: 99.26%\n",
      "11\tValidation loss: 0.051602\tBest loss: 0.034234\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.038714\tBest loss: 0.034234\tAccuracy: 99.02%\n",
      "13\tValidation loss: 0.028449\tBest loss: 0.028449\tAccuracy: 99.61%\n",
      "14\tValidation loss: 0.052004\tBest loss: 0.028449\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.031264\tBest loss: 0.028449\tAccuracy: 99.34%\n",
      "16\tValidation loss: 0.046731\tBest loss: 0.028449\tAccuracy: 99.10%\n",
      "17\tValidation loss: 0.038823\tBest loss: 0.028449\tAccuracy: 99.18%\n",
      "18\tValidation loss: 0.023834\tBest loss: 0.023834\tAccuracy: 99.57%\n",
      "19\tValidation loss: 0.049966\tBest loss: 0.023834\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.044796\tBest loss: 0.023834\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.024424\tBest loss: 0.023834\tAccuracy: 99.34%\n",
      "22\tValidation loss: 0.031150\tBest loss: 0.023834\tAccuracy: 99.14%\n",
      "23\tValidation loss: 0.041066\tBest loss: 0.023834\tAccuracy: 99.10%\n",
      "24\tValidation loss: 0.031811\tBest loss: 0.023834\tAccuracy: 99.34%\n",
      "25\tValidation loss: 0.035214\tBest loss: 0.023834\tAccuracy: 99.49%\n",
      "26\tValidation loss: 0.037161\tBest loss: 0.023834\tAccuracy: 99.30%\n",
      "27\tValidation loss: 0.037892\tBest loss: 0.023834\tAccuracy: 99.10%\n",
      "28\tValidation loss: 0.037999\tBest loss: 0.023834\tAccuracy: 99.26%\n",
      "29\tValidation loss: 0.031245\tBest loss: 0.023834\tAccuracy: 99.49%\n",
      "30\tValidation loss: 0.047663\tBest loss: 0.023834\tAccuracy: 99.34%\n",
      "31\tValidation loss: 0.038467\tBest loss: 0.023834\tAccuracy: 99.37%\n",
      "32\tValidation loss: 0.065151\tBest loss: 0.023834\tAccuracy: 98.83%\n",
      "33\tValidation loss: 0.043235\tBest loss: 0.023834\tAccuracy: 99.14%\n",
      "34\tValidation loss: 0.054375\tBest loss: 0.023834\tAccuracy: 99.18%\n",
      "35\tValidation loss: 0.037003\tBest loss: 0.023834\tAccuracy: 99.45%\n",
      "36\tValidation loss: 0.050301\tBest loss: 0.023834\tAccuracy: 99.22%\n",
      "37\tValidation loss: 0.047442\tBest loss: 0.023834\tAccuracy: 99.30%\n",
      "38\tValidation loss: 0.052852\tBest loss: 0.023834\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./savepoints/MNIST_take_two.ckpt\n",
      "Final test accuracy: 99.24%\n"
     ]
    }
   ],
   "source": [
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid1, y: y_valid1})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./savepoints/MNIST_take_two.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./savepoints/MNIST_take_two.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
